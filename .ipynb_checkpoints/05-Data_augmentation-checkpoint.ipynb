{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation using ImageDataGenerator in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will seek to build on previously built model's by exploiting Keras' built in data augmentation functionality. The ```ImageDataGenerator``` class provides an infinite stream of manipulated images. It takes in the training data as normal and outputs images that have been transformed, rotated, shifted, and flipped. \n",
    "\n",
    "These new images provide the basis for a new training set for the neural network, with the hope that introducing some new changes will help the network discover new patterns in the data it could not with the fixed training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "%run __initremote__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('60_epoch_adam.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_acc', \n",
    "                                           min_delta=0, \n",
    "                                           patience=10, \n",
    "                                           verbose=0, \n",
    "                                           mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.7741 - acc: 0.7550 - val_loss: 0.5788 - val_acc: 0.8067\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.7293 - acc: 0.7562 - val_loss: 0.5719 - val_acc: 0.8077\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.7093 - acc: 0.7614 - val_loss: 0.5646 - val_acc: 0.8086\n",
      "Epoch 4/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.6967 - acc: 0.7641 - val_loss: 0.5637 - val_acc: 0.8102\n",
      "Epoch 5/100\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.6833 - acc: 0.7656 - val_loss: 0.5620 - val_acc: 0.8129\n",
      "Epoch 6/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.6850 - acc: 0.7679 - val_loss: 0.5670 - val_acc: 0.8093\n",
      "Epoch 7/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.6765 - acc: 0.7701 - val_loss: 0.5562 - val_acc: 0.8143\n",
      "Epoch 8/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.6687 - acc: 0.7729 - val_loss: 0.5534 - val_acc: 0.8160\n",
      "Epoch 9/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.6645 - acc: 0.7758 - val_loss: 0.5491 - val_acc: 0.8168\n",
      "Epoch 10/100\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.6557 - acc: 0.7765 - val_loss: 0.5475 - val_acc: 0.8145\n",
      "Epoch 11/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.6494 - acc: 0.7795 - val_loss: 0.5494 - val_acc: 0.8145\n",
      "Epoch 12/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.6519 - acc: 0.7769 - val_loss: 0.5448 - val_acc: 0.8177\n",
      "Epoch 13/100\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.6405 - acc: 0.7806 - val_loss: 0.5440 - val_acc: 0.8164\n",
      "Epoch 14/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.6397 - acc: 0.7810 - val_loss: 0.5438 - val_acc: 0.8160\n",
      "Epoch 15/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.6369 - acc: 0.7819 - val_loss: 0.5421 - val_acc: 0.8170\n",
      "Epoch 16/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.6325 - acc: 0.7834 - val_loss: 0.5364 - val_acc: 0.8198\n",
      "Epoch 17/100\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.6303 - acc: 0.7845 - val_loss: 0.5404 - val_acc: 0.8190\n",
      "Epoch 18/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.6259 - acc: 0.7853 - val_loss: 0.5324 - val_acc: 0.8202\n",
      "Epoch 19/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.6186 - acc: 0.7868 - val_loss: 0.5361 - val_acc: 0.8168\n",
      "Epoch 20/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.6082 - acc: 0.7898 - val_loss: 0.5252 - val_acc: 0.8222\n",
      "Epoch 24/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.6026 - acc: 0.7947 - val_loss: 0.5252 - val_acc: 0.8225\n",
      "Epoch 25/100\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.6031 - acc: 0.7930 - val_loss: 0.5219 - val_acc: 0.8244\n",
      "Epoch 26/100\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.6007 - acc: 0.7946 - val_loss: 0.5207 - val_acc: 0.8260\n",
      "Epoch 27/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.6017 - acc: 0.7918 - val_loss: 0.5186 - val_acc: 0.8265\n",
      "Epoch 28/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5977 - acc: 0.7932 - val_loss: 0.5169 - val_acc: 0.8271\n",
      "Epoch 29/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5999 - acc: 0.7939 - val_loss: 0.5207 - val_acc: 0.8253\n",
      "Epoch 30/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5949 - acc: 0.7940 - val_loss: 0.5123 - val_acc: 0.8270\n",
      "Epoch 31/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5868 - acc: 0.7993 - val_loss: 0.5190 - val_acc: 0.8274\n",
      "Epoch 32/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5875 - acc: 0.7978 - val_loss: 0.5116 - val_acc: 0.8263\n",
      "Epoch 33/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5866 - acc: 0.7972 - val_loss: 0.5103 - val_acc: 0.8269\n",
      "Epoch 34/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5826 - acc: 0.7991 - val_loss: 0.5097 - val_acc: 0.8303\n",
      "Epoch 35/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5834 - acc: 0.7994 - val_loss: 0.5127 - val_acc: 0.8275\n",
      "Epoch 36/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5767 - acc: 0.8015 - val_loss: 0.5072 - val_acc: 0.8300\n",
      "Epoch 37/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5778 - acc: 0.7991 - val_loss: 0.5135 - val_acc: 0.8274\n",
      "Epoch 38/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5686 - acc: 0.8036 - val_loss: 0.5139 - val_acc: 0.8254\n",
      "Epoch 39/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5733 - acc: 0.8012 - val_loss: 0.5019 - val_acc: 0.8292\n",
      "Epoch 40/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5711 - acc: 0.8035 - val_loss: 0.4988 - val_acc: 0.8299\n",
      "Epoch 41/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5734 - acc: 0.8012 - val_loss: 0.5076 - val_acc: 0.8270\n",
      "Epoch 42/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5655 - acc: 0.8055 - val_loss: 0.5021 - val_acc: 0.8290\n",
      "Epoch 43/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5628 - acc: 0.8062 - val_loss: 0.4979 - val_acc: 0.8328\n",
      "Epoch 44/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5638 - acc: 0.8053 - val_loss: 0.4975 - val_acc: 0.8326\n",
      "Epoch 45/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5743 - acc: 0.7995 - val_loss: 0.5049 - val_acc: 0.8318\n",
      "Epoch 46/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5652 - acc: 0.8044 - val_loss: 0.5024 - val_acc: 0.8295\n",
      "Epoch 47/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5614 - acc: 0.8044 - val_loss: 0.5042 - val_acc: 0.8303\n",
      "Epoch 48/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5559 - acc: 0.8089 - val_loss: 0.4988 - val_acc: 0.8332\n",
      "Epoch 49/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5542 - acc: 0.8086 - val_loss: 0.4990 - val_acc: 0.8306\n",
      "Epoch 50/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5517 - acc: 0.8107 - val_loss: 0.5025 - val_acc: 0.8327\n",
      "Epoch 51/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5503 - acc: 0.8087 - val_loss: 0.4950 - val_acc: 0.8335\n",
      "Epoch 52/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5477 - acc: 0.8094 - val_loss: 0.4961 - val_acc: 0.8348\n",
      "Epoch 53/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5514 - acc: 0.8095 - val_loss: 0.4882 - val_acc: 0.8364\n",
      "Epoch 54/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5531 - acc: 0.8072 - val_loss: 0.4886 - val_acc: 0.8348\n",
      "Epoch 55/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5459 - acc: 0.8108 - val_loss: 0.4893 - val_acc: 0.8364\n",
      "Epoch 56/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5465 - acc: 0.8109 - val_loss: 0.4962 - val_acc: 0.8327\n",
      "Epoch 57/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5473 - acc: 0.8115 - val_loss: 0.4918 - val_acc: 0.8332\n",
      "Epoch 58/100\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.5428 - acc: 0.8119 - val_loss: 0.4949 - val_acc: 0.8319\n",
      "Epoch 59/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5391 - acc: 0.8120 - val_loss: 0.4962 - val_acc: 0.8337\n",
      "Epoch 60/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5413 - acc: 0.8119 - val_loss: 0.4950 - val_acc: 0.8373\n",
      "Epoch 61/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5377 - acc: 0.8136 - val_loss: 0.4936 - val_acc: 0.8351\n",
      "Epoch 62/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5345 - acc: 0.8154 - val_loss: 0.4886 - val_acc: 0.8359\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5310 - acc: 0.8151 - val_loss: 0.4771 - val_acc: 0.8387\n",
      "Epoch 64/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5361 - acc: 0.8152 - val_loss: 0.4878 - val_acc: 0.8342\n",
      "Epoch 65/100\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.5291 - acc: 0.8157 - val_loss: 0.4834 - val_acc: 0.8366\n",
      "Epoch 66/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5317 - acc: 0.8153 - val_loss: 0.4845 - val_acc: 0.8369\n",
      "Epoch 67/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5291 - acc: 0.8152 - val_loss: 0.4791 - val_acc: 0.8380\n",
      "Epoch 68/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5242 - acc: 0.8189 - val_loss: 0.4823 - val_acc: 0.8371\n",
      "Epoch 69/100\n",
      "1563/1563 [==============================] - 47s 30ms/step - loss: 0.5299 - acc: 0.8178 - val_loss: 0.4772 - val_acc: 0.8401\n",
      "Epoch 70/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5275 - acc: 0.8167 - val_loss: 0.4781 - val_acc: 0.8389\n",
      "Epoch 71/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5191 - acc: 0.8198 - val_loss: 0.4765 - val_acc: 0.8399\n",
      "Epoch 72/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5232 - acc: 0.8188 - val_loss: 0.4814 - val_acc: 0.8378\n",
      "Epoch 73/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5286 - acc: 0.8170 - val_loss: 0.4880 - val_acc: 0.8365\n",
      "Epoch 74/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5231 - acc: 0.8198 - val_loss: 0.4753 - val_acc: 0.8409\n",
      "Epoch 75/100\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.5185 - acc: 0.8203 - val_loss: 0.4750 - val_acc: 0.8409\n",
      "Epoch 76/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5188 - acc: 0.8194 - val_loss: 0.4679 - val_acc: 0.8406\n",
      "Epoch 80/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5151 - acc: 0.8230 - val_loss: 0.4744 - val_acc: 0.8409\n",
      "Epoch 81/100\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.5093 - acc: 0.8241 - val_loss: 0.4756 - val_acc: 0.8406\n",
      "Epoch 82/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5106 - acc: 0.8217 - val_loss: 0.4795 - val_acc: 0.8389\n",
      "Epoch 83/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5078 - acc: 0.8225 - val_loss: 0.4665 - val_acc: 0.8421\n",
      "Epoch 84/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5119 - acc: 0.8225 - val_loss: 0.4678 - val_acc: 0.8439\n",
      "Epoch 85/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5143 - acc: 0.8209 - val_loss: 0.4677 - val_acc: 0.8436\n",
      "Epoch 86/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5089 - acc: 0.8222 - val_loss: 0.4626 - val_acc: 0.8442\n",
      "Epoch 87/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5018 - acc: 0.8252 - val_loss: 0.4645 - val_acc: 0.8453\n",
      "Epoch 88/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5045 - acc: 0.8247 - val_loss: 0.4663 - val_acc: 0.8416\n",
      "Epoch 89/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5066 - acc: 0.8254 - val_loss: 0.4573 - val_acc: 0.8459\n",
      "Epoch 90/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5063 - acc: 0.8237 - val_loss: 0.4579 - val_acc: 0.8467\n",
      "Epoch 91/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.4968 - acc: 0.8265 - val_loss: 0.4559 - val_acc: 0.8453\n",
      "Epoch 92/100\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.5006 - acc: 0.8264 - val_loss: 0.4651 - val_acc: 0.8438\n",
      "Epoch 93/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.4979 - acc: 0.8267 - val_loss: 0.4705 - val_acc: 0.8414\n",
      "Epoch 94/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.5011 - acc: 0.8282 - val_loss: 0.4684 - val_acc: 0.8441\n",
      "Epoch 95/100\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.4988 - acc: 0.8261 - val_loss: 0.4603 - val_acc: 0.8480\n",
      "Epoch 96/100\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.4908 - acc: 0.8286 - val_loss: 0.4645 - val_acc: 0.8451\n",
      "Epoch 97/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.4948 - acc: 0.8291 - val_loss: 0.4665 - val_acc: 0.8431\n",
      "Epoch 98/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.4967 - acc: 0.8267 - val_loss: 0.4731 - val_acc: 0.8408\n",
      "Epoch 99/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.4925 - acc: 0.8294 - val_loss: 0.4560 - val_acc: 0.8488\n",
      "Epoch 100/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.4953 - acc: 0.8271 - val_loss: 0.4621 - val_acc: 0.8460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f856129cb70>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=0, \n",
    "                             width_shift_range=0.1, \n",
    "                             height_shift_range=0.1, \n",
    "                             horizontal_flip=True)\n",
    "\n",
    "datagen.fit(x_train)\n",
    "\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=32),\n",
    "                   epochs=100,\n",
    "                   validation_data=(x_test, y_test),\n",
    "                   callbacks=[early_stop],\n",
    "                   workers=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 100 epochs, the model is still learning while using the ```datagen.flow``` method. Let's run it for another 100 epochs and see if it can get a bit smarter. At this point the model has been training for approximately 80 minutes, not including prior learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.4977 - acc: 0.8276 - val_loss: 0.4594 - val_acc: 0.8470\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.4913 - acc: 0.8301 - val_loss: 0.4615 - val_acc: 0.8476\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 46s 30ms/step - loss: 0.4863 - acc: 0.8311 - val_loss: 0.4654 - val_acc: 0.8446\n",
      "Epoch 4/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.4938 - acc: 0.8292 - val_loss: 0.4645 - val_acc: 0.8439\n",
      "Epoch 5/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.4865 - acc: 0.8306 - val_loss: 0.4589 - val_acc: 0.8469\n",
      "Epoch 6/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.4863 - acc: 0.8311 - val_loss: 0.4590 - val_acc: 0.8463\n",
      "Epoch 7/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.4840 - acc: 0.8322 - val_loss: 0.4586 - val_acc: 0.8452\n",
      "Epoch 8/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.4880 - acc: 0.8315 - val_loss: 0.4505 - val_acc: 0.8503\n",
      "Epoch 9/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.4832 - acc: 0.8306 - val_loss: 0.4534 - val_acc: 0.8487\n",
      "Epoch 10/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.4843 - acc: 0.8323 - val_loss: 0.4470 - val_acc: 0.8500\n",
      "Epoch 11/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.4877 - acc: 0.8328 - val_loss: 0.4652 - val_acc: 0.8461\n",
      "Epoch 12/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.4839 - acc: 0.8327 - val_loss: 0.4536 - val_acc: 0.8495\n",
      "Epoch 13/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.4836 - acc: 0.8324 - val_loss: 0.4642 - val_acc: 0.8470\n",
      "Epoch 14/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.4835 - acc: 0.8322 - val_loss: 0.4625 - val_acc: 0.8459\n",
      "Epoch 15/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.4742 - acc: 0.8349 - val_loss: 0.4616 - val_acc: 0.8482\n",
      "Epoch 18/100\n",
      "1563/1563 [==============================] - 46s 29ms/step - loss: 0.4789 - acc: 0.8318 - val_loss: 0.4553 - val_acc: 0.8459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f856129c978>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=32),\n",
    "                   epochs=100,\n",
    "                   validation_data=(x_test, y_test),\n",
    "                   callbacks=[early_stop],\n",
    "                   workers=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 146us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.45529800367355344, 0.84589999999999999]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('datagen_115.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional training was not able to significantly help the model learn. Currently, it tests at a 84.6% accuracy, with a test error rate of 15.4%. This result is starting to be comparative to other benchmark models for CIFAR-10, referenced on the cs.toronto.edu readme page. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From cs.toronto.edu: \"You can find some baseline replicable results on this dataset on the project page for cuda-convnet. These results were obtained with a convolutional neural network. Briefly, they are 18% test error without data augmentation and 11% with.\" See http://code.google.com/p/cuda-convnet/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to data augmentation, the test error rate was just about 18.5%, again comparative to the baseline results of work done elsewhere. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
