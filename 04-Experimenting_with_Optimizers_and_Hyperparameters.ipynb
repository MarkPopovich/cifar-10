{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Optimization\n",
    "\n",
    "In this notebook I will seek to experiment with the different hyperparameters inherint in building neural networks. I will hold constant the architecture of the network itself by building a function to define identitical networks with set features. I will then fit these identical networks with a wide range of hyperparameters, including the optimization function itself, the learning rate, decay, and type of loss calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "%run __initremote__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_acc', \n",
    "                                           min_delta=0, \n",
    "                                           patience=5, \n",
    "                                           verbose=0, \n",
    "                                           mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_network():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "opt_1 = standard_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "opt_1.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 24s 477us/step - loss: 1.8119 - acc: 0.3346 - val_loss: 1.5740 - val_acc: 0.4272\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 23s 454us/step - loss: 1.4980 - acc: 0.4584 - val_loss: 1.3740 - val_acc: 0.5068\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.3647 - acc: 0.5092 - val_loss: 1.2652 - val_acc: 0.5540\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 1.2737 - acc: 0.5452 - val_loss: 1.2644 - val_acc: 0.5599\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 23s 454us/step - loss: 1.1984 - acc: 0.5758 - val_loss: 1.0985 - val_acc: 0.6207\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 1.1378 - acc: 0.6004 - val_loss: 1.0858 - val_acc: 0.6215\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.0773 - acc: 0.6235 - val_loss: 0.9859 - val_acc: 0.6537\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 1.0305 - acc: 0.6394 - val_loss: 0.9619 - val_acc: 0.6686\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 23s 454us/step - loss: 0.9908 - acc: 0.6524 - val_loss: 0.9074 - val_acc: 0.6841\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.9504 - acc: 0.6702 - val_loss: 0.8789 - val_acc: 0.6952\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.9137 - acc: 0.6824 - val_loss: 0.9008 - val_acc: 0.6905\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 23s 454us/step - loss: 0.8889 - acc: 0.6902 - val_loss: 0.8414 - val_acc: 0.7083\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.8624 - acc: 0.7006 - val_loss: 0.8542 - val_acc: 0.7043\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 23s 455us/step - loss: 0.8365 - acc: 0.7109 - val_loss: 0.8150 - val_acc: 0.7185\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.8197 - acc: 0.7173 - val_loss: 0.7978 - val_acc: 0.7251\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.8049 - acc: 0.7250 - val_loss: 0.7920 - val_acc: 0.7279\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.7861 - acc: 0.7275 - val_loss: 0.7431 - val_acc: 0.7429\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.7799 - acc: 0.7305 - val_loss: 0.7535 - val_acc: 0.7414\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.7608 - acc: 0.7379 - val_loss: 0.7562 - val_acc: 0.7411\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.7525 - acc: 0.7408 - val_loss: 0.7541 - val_acc: 0.7447\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.7447 - acc: 0.7434 - val_loss: 0.7227 - val_acc: 0.7534\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 0.7355 - acc: 0.7489 - val_loss: 0.7187 - val_acc: 0.7531\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 0.7265 - acc: 0.7503 - val_loss: 0.7258 - val_acc: 0.7594\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 22s 450us/step - loss: 0.7219 - acc: 0.7510 - val_loss: 0.7224 - val_acc: 0.7574\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 23s 450us/step - loss: 0.7121 - acc: 0.7561 - val_loss: 0.7036 - val_acc: 0.7636\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 22s 450us/step - loss: 0.7049 - acc: 0.7589 - val_loss: 0.7903 - val_acc: 0.7329\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 23s 450us/step - loss: 0.7046 - acc: 0.7597 - val_loss: 0.6987 - val_acc: 0.7694\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 23s 450us/step - loss: 0.6966 - acc: 0.7626 - val_loss: 0.7428 - val_acc: 0.7494\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 22s 450us/step - loss: 0.6981 - acc: 0.7625 - val_loss: 0.6903 - val_acc: 0.7726\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 22s 450us/step - loss: 0.6925 - acc: 0.7661 - val_loss: 0.7027 - val_acc: 0.7708\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 22s 450us/step - loss: 0.6870 - acc: 0.7677 - val_loss: 0.7097 - val_acc: 0.7649\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 22s 450us/step - loss: 0.6840 - acc: 0.7672 - val_loss: 0.7000 - val_acc: 0.7665\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 22s 450us/step - loss: 0.6768 - acc: 0.7703 - val_loss: 0.7174 - val_acc: 0.7645\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 23s 450us/step - loss: 0.6739 - acc: 0.7725 - val_loss: 0.6968 - val_acc: 0.7722\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8eb64d22e8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_1.fit(x_train, y_train,\n",
    "              batch_size=32,\n",
    "              epochs=100,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 147us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.69683952236175539, 0.7722]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_1.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This represents the baseline model recreated from the Keras example repository for CIFAR-10. What happens to the model's performance if the learning rate is increased? What about decreased? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 23s 457us/step - loss: 1.5304 - acc: 0.4474 - val_loss: 1.2639 - val_acc: 0.5637\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 22s 450us/step - loss: 1.1348 - acc: 0.6047 - val_loss: 1.0025 - val_acc: 0.6527\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.0137 - acc: 0.6514 - val_loss: 1.2495 - val_acc: 0.6150\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 0.9807 - acc: 0.6650 - val_loss: 0.9566 - val_acc: 0.6673\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.9879 - acc: 0.6720 - val_loss: 1.4668 - val_acc: 0.6240\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.0133 - acc: 0.6664 - val_loss: 0.8933 - val_acc: 0.7032\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 23s 450us/step - loss: 1.0474 - acc: 0.6592 - val_loss: 0.8694 - val_acc: 0.7117\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.0824 - acc: 0.6525 - val_loss: 1.2667 - val_acc: 0.5786\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 1.1102 - acc: 0.6426 - val_loss: 1.1168 - val_acc: 0.6368\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 1.1381 - acc: 0.6343 - val_loss: 1.3243 - val_acc: 0.5923\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 1.1755 - acc: 0.6248 - val_loss: 0.9671 - val_acc: 0.6802\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 1.2056 - acc: 0.6139 - val_loss: 1.5240 - val_acc: 0.5186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8eb4e234a8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_2_lr_inc = standard_network()\n",
    "\n",
    "opt = keras.optimizers.RMSprop(lr=0.001, decay=1e-6)\n",
    "opt_2_lr_inc.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "opt_2_lr_inc.fit(x_train, y_train,\n",
    "              batch_size=32,\n",
    "              epochs=100,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 147us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5240188974380493, 0.51859999999999995]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_2_lr_inc.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning rate parameter modulates how large of steps the model takes on the backward propagation pass. In other words, how large of steps does it take during the gradient descent. When the learning rate increases, larger steps are made. This could potentially lead to 'overshooting' the minimum of the function. Indeed, as we see above, the model approaches 71% accuracy on epoch 7 (fairly quickly compared to previous models) but drops down from there. Instead of making very small steps towards the minimum, the model makes big, clunky steps and overshoots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 23s 459us/step - loss: 2.2419 - acc: 0.1579 - val_loss: 2.0904 - val_acc: 0.2571\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 2.0415 - acc: 0.2430 - val_loss: 1.9564 - val_acc: 0.3143\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 1.9362 - acc: 0.2947 - val_loss: 1.8297 - val_acc: 0.3699\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.8214 - acc: 0.3439 - val_loss: 1.7255 - val_acc: 0.3981\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.7484 - acc: 0.3695 - val_loss: 1.6641 - val_acc: 0.4168\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.6914 - acc: 0.3852 - val_loss: 1.6141 - val_acc: 0.4258\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.6501 - acc: 0.4002 - val_loss: 1.5686 - val_acc: 0.4411\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.6112 - acc: 0.4138 - val_loss: 1.5417 - val_acc: 0.4478\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.5825 - acc: 0.4251 - val_loss: 1.5134 - val_acc: 0.4555\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.5616 - acc: 0.4304 - val_loss: 1.4920 - val_acc: 0.4643\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.5349 - acc: 0.4403 - val_loss: 1.4646 - val_acc: 0.4736\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.5113 - acc: 0.4498 - val_loss: 1.4552 - val_acc: 0.4735\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.4917 - acc: 0.4583 - val_loss: 1.4242 - val_acc: 0.4883\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.4725 - acc: 0.4656 - val_loss: 1.4056 - val_acc: 0.4960\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 23s 455us/step - loss: 1.4559 - acc: 0.4721 - val_loss: 1.3949 - val_acc: 0.5025\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 1.4410 - acc: 0.4781 - val_loss: 1.3739 - val_acc: 0.5103\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.4253 - acc: 0.4868 - val_loss: 1.3617 - val_acc: 0.5143\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.4100 - acc: 0.4930 - val_loss: 1.3444 - val_acc: 0.5241\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.3947 - acc: 0.4970 - val_loss: 1.3319 - val_acc: 0.5254\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.3800 - acc: 0.5023 - val_loss: 1.3200 - val_acc: 0.5340\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.3682 - acc: 0.5115 - val_loss: 1.3079 - val_acc: 0.5390\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.3587 - acc: 0.5130 - val_loss: 1.2998 - val_acc: 0.5391\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.3427 - acc: 0.5191 - val_loss: 1.2865 - val_acc: 0.5442\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.3357 - acc: 0.5232 - val_loss: 1.2924 - val_acc: 0.5392\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.3196 - acc: 0.5292 - val_loss: 1.2607 - val_acc: 0.5531\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.3117 - acc: 0.5313 - val_loss: 1.2456 - val_acc: 0.5595\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.2992 - acc: 0.5395 - val_loss: 1.2405 - val_acc: 0.5600\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.2911 - acc: 0.5397 - val_loss: 1.2392 - val_acc: 0.5638\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.2788 - acc: 0.5461 - val_loss: 1.2261 - val_acc: 0.5675\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 1.2707 - acc: 0.5485 - val_loss: 1.2172 - val_acc: 0.5705\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.2610 - acc: 0.5515 - val_loss: 1.1964 - val_acc: 0.5776\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.2506 - acc: 0.5555 - val_loss: 1.1932 - val_acc: 0.5815\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 1.2457 - acc: 0.5614 - val_loss: 1.1852 - val_acc: 0.5831\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 1.2339 - acc: 0.5616 - val_loss: 1.1831 - val_acc: 0.5811\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 1.2274 - acc: 0.5638 - val_loss: 1.1614 - val_acc: 0.5913\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.2193 - acc: 0.5686 - val_loss: 1.1728 - val_acc: 0.5850\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.2128 - acc: 0.5721 - val_loss: 1.1464 - val_acc: 0.5968\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 1.2025 - acc: 0.5759 - val_loss: 1.1431 - val_acc: 0.5978\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.1950 - acc: 0.5758 - val_loss: 1.1473 - val_acc: 0.5955\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 1.1848 - acc: 0.5806 - val_loss: 1.1274 - val_acc: 0.6076\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 1.1761 - acc: 0.5856 - val_loss: 1.1222 - val_acc: 0.6060\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 23s 454us/step - loss: 1.1681 - acc: 0.5879 - val_loss: 1.1163 - val_acc: 0.6087\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 1.1655 - acc: 0.5888 - val_loss: 1.1092 - val_acc: 0.6129\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 1.1591 - acc: 0.5918 - val_loss: 1.1036 - val_acc: 0.6157\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.1508 - acc: 0.5945 - val_loss: 1.0987 - val_acc: 0.6165\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 23s 454us/step - loss: 1.1433 - acc: 0.5995 - val_loss: 1.0833 - val_acc: 0.6219\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.1372 - acc: 0.5988 - val_loss: 1.0804 - val_acc: 0.6240\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.1336 - acc: 0.6000 - val_loss: 1.0764 - val_acc: 0.6226\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.1253 - acc: 0.6041 - val_loss: 1.0621 - val_acc: 0.6283\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.1169 - acc: 0.6068 - val_loss: 1.0710 - val_acc: 0.6261\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 1.1104 - acc: 0.6121 - val_loss: 1.0579 - val_acc: 0.6324\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.1100 - acc: 0.6092 - val_loss: 1.0516 - val_acc: 0.6334\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 1.0994 - acc: 0.6143 - val_loss: 1.0400 - val_acc: 0.6384\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.0931 - acc: 0.6166 - val_loss: 1.0388 - val_acc: 0.6359\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.0902 - acc: 0.6183 - val_loss: 1.0484 - val_acc: 0.6370\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.0817 - acc: 0.6200 - val_loss: 1.0288 - val_acc: 0.6400\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 23s 456us/step - loss: 1.0788 - acc: 0.6205 - val_loss: 1.0242 - val_acc: 0.6431\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 23s 457us/step - loss: 1.0704 - acc: 0.6243 - val_loss: 1.0133 - val_acc: 0.6452\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 23s 459us/step - loss: 1.0652 - acc: 0.6273 - val_loss: 1.0077 - val_acc: 0.6499\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 23s 458us/step - loss: 1.0621 - acc: 0.6277 - val_loss: 1.0099 - val_acc: 0.6468\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 23s 459us/step - loss: 1.0531 - acc: 0.6331 - val_loss: 1.0009 - val_acc: 0.6509\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 23s 461us/step - loss: 1.0515 - acc: 0.6304 - val_loss: 1.0111 - val_acc: 0.6484\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 23s 461us/step - loss: 1.0457 - acc: 0.6333 - val_loss: 0.9944 - val_acc: 0.6564\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 23s 460us/step - loss: 1.0415 - acc: 0.6346 - val_loss: 0.9913 - val_acc: 0.6563\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 23s 459us/step - loss: 1.0359 - acc: 0.6375 - val_loss: 0.9828 - val_acc: 0.6583\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 23s 458us/step - loss: 1.0330 - acc: 0.6390 - val_loss: 0.9797 - val_acc: 0.6584\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 23s 458us/step - loss: 1.0277 - acc: 0.6399 - val_loss: 0.9784 - val_acc: 0.6579\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 23s 458us/step - loss: 1.0244 - acc: 0.6415 - val_loss: 0.9800 - val_acc: 0.6574\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 23s 458us/step - loss: 1.0161 - acc: 0.6431 - val_loss: 0.9654 - val_acc: 0.6655\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 23s 459us/step - loss: 1.0177 - acc: 0.6438 - val_loss: 0.9720 - val_acc: 0.6607\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 23s 458us/step - loss: 1.0112 - acc: 0.6478 - val_loss: 0.9616 - val_acc: 0.6681\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 23s 459us/step - loss: 1.0083 - acc: 0.6468 - val_loss: 0.9567 - val_acc: 0.6687\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 23s 458us/step - loss: 1.0033 - acc: 0.6477 - val_loss: 0.9583 - val_acc: 0.6653\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 23s 457us/step - loss: 0.9974 - acc: 0.6515 - val_loss: 0.9543 - val_acc: 0.6707\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 23s 460us/step - loss: 0.9941 - acc: 0.6511 - val_loss: 0.9483 - val_acc: 0.6734\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 23s 457us/step - loss: 0.9905 - acc: 0.6554 - val_loss: 0.9440 - val_acc: 0.6707\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 23s 458us/step - loss: 0.9917 - acc: 0.6525 - val_loss: 0.9434 - val_acc: 0.6737\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 23s 459us/step - loss: 0.9833 - acc: 0.6571 - val_loss: 0.9345 - val_acc: 0.6759\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 23s 460us/step - loss: 0.9786 - acc: 0.6574 - val_loss: 0.9355 - val_acc: 0.6796\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 23s 461us/step - loss: 0.9763 - acc: 0.6579 - val_loss: 0.9295 - val_acc: 0.6782\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 23s 460us/step - loss: 0.9718 - acc: 0.6581 - val_loss: 0.9277 - val_acc: 0.6799\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 23s 461us/step - loss: 0.9679 - acc: 0.6605 - val_loss: 0.9363 - val_acc: 0.6813\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 23s 460us/step - loss: 0.9667 - acc: 0.6630 - val_loss: 0.9259 - val_acc: 0.6801\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 23s 462us/step - loss: 0.9664 - acc: 0.6618 - val_loss: 0.9244 - val_acc: 0.6812\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 23s 462us/step - loss: 0.9583 - acc: 0.6638 - val_loss: 0.9147 - val_acc: 0.6859\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 23s 459us/step - loss: 0.9567 - acc: 0.6646 - val_loss: 0.9102 - val_acc: 0.6858\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 23s 459us/step - loss: 0.9545 - acc: 0.6650 - val_loss: 0.9091 - val_acc: 0.6874\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 23s 458us/step - loss: 0.9534 - acc: 0.6686 - val_loss: 0.9156 - val_acc: 0.6828\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 23s 460us/step - loss: 0.9476 - acc: 0.6702 - val_loss: 0.9153 - val_acc: 0.6852\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 23s 458us/step - loss: 0.9421 - acc: 0.6712 - val_loss: 0.9100 - val_acc: 0.6851\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 23s 457us/step - loss: 0.9393 - acc: 0.6738 - val_loss: 0.8955 - val_acc: 0.6917\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 23s 458us/step - loss: 0.9363 - acc: 0.6742 - val_loss: 0.8948 - val_acc: 0.6908\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 23s 458us/step - loss: 0.9334 - acc: 0.6754 - val_loss: 0.8945 - val_acc: 0.6898\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 23s 459us/step - loss: 0.9363 - acc: 0.6739 - val_loss: 0.8949 - val_acc: 0.6925\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 23s 456us/step - loss: 0.9312 - acc: 0.6763 - val_loss: 0.8876 - val_acc: 0.6938\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 23s 457us/step - loss: 0.9268 - acc: 0.6771 - val_loss: 0.8904 - val_acc: 0.6931\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 23s 457us/step - loss: 0.9217 - acc: 0.6778 - val_loss: 0.8850 - val_acc: 0.6941\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 23s 458us/step - loss: 0.9203 - acc: 0.6795 - val_loss: 0.8880 - val_acc: 0.6930\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 23s 457us/step - loss: 0.9208 - acc: 0.6782 - val_loss: 0.8827 - val_acc: 0.6947\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 23s 458us/step - loss: 0.9167 - acc: 0.6794 - val_loss: 0.8793 - val_acc: 0.6974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8e8c5d7e10>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_2_lr_dec = standard_network()\n",
    "\n",
    "opt = keras.optimizers.RMSprop(lr=0.00001, decay=1e-6)\n",
    "opt_2_lr_dec.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "opt_2_lr_dec.fit(x_train, y_train,\n",
    "              batch_size=32,\n",
    "              epochs=100,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a lower learning rate, even after 100 epochs the model continues to learn. However, despite many epochs, validation accuracy remains below the accuracy achieved after only 34 epochs with the standard learning rate.\n",
    "\n",
    "Below I will run the model for another 100 epochs to see whether it continues to learn, and if so for how long. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 23s 462us/step - loss: 0.9135 - acc: 0.6805 - val_loss: 0.8700 - val_acc: 0.7020\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 23s 460us/step - loss: 0.9093 - acc: 0.6838 - val_loss: 0.8738 - val_acc: 0.6977\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 0.8956 - acc: 0.6854 - val_loss: 0.8612 - val_acc: 0.7026\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 22s 450us/step - loss: 0.8905 - acc: 0.6897 - val_loss: 0.8591 - val_acc: 0.7039\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 23s 450us/step - loss: 0.8911 - acc: 0.6903 - val_loss: 0.8571 - val_acc: 0.7061\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 23s 450us/step - loss: 0.8890 - acc: 0.6886 - val_loss: 0.8537 - val_acc: 0.7063\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 23s 450us/step - loss: 0.8867 - acc: 0.6905 - val_loss: 0.8538 - val_acc: 0.7081\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 22s 450us/step - loss: 0.8854 - acc: 0.6922 - val_loss: 0.8470 - val_acc: 0.7083\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 23s 450us/step - loss: 0.8790 - acc: 0.6943 - val_loss: 0.8459 - val_acc: 0.7111\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 22s 449us/step - loss: 0.8761 - acc: 0.6945 - val_loss: 0.8465 - val_acc: 0.7109\n",
      "Epoch 16/100\n",
      "11552/50000 [=====>........................] - ETA: 16s - loss: 0.8680 - acc: 0.6971"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 22s 450us/step - loss: 0.8571 - acc: 0.7029 - val_loss: 0.8297 - val_acc: 0.7149\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 22s 450us/step - loss: 0.8518 - acc: 0.7038 - val_loss: 0.8256 - val_acc: 0.7175\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 23s 450us/step - loss: 0.8486 - acc: 0.7023 - val_loss: 0.8191 - val_acc: 0.7193\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 22s 450us/step - loss: 0.8474 - acc: 0.7049 - val_loss: 0.8206 - val_acc: 0.7222\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 23s 450us/step - loss: 0.8459 - acc: 0.7073 - val_loss: 0.8214 - val_acc: 0.7194\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 22s 450us/step - loss: 0.8476 - acc: 0.7056 - val_loss: 0.8204 - val_acc: 0.7227\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 22s 450us/step - loss: 0.8447 - acc: 0.7049 - val_loss: 0.8163 - val_acc: 0.7219\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 23s 450us/step - loss: 0.8404 - acc: 0.7087 - val_loss: 0.8262 - val_acc: 0.7198\n",
      "Epoch 34/100\n",
      " 1184/50000 [..............................] - ETA: 20s - loss: 0.8542 - acc: 0.7010"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 22s 450us/step - loss: 0.8236 - acc: 0.7129 - val_loss: 0.8023 - val_acc: 0.7285\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 22s 449us/step - loss: 0.8247 - acc: 0.7128 - val_loss: 0.8021 - val_acc: 0.7287\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 23s 450us/step - loss: 0.8246 - acc: 0.7137 - val_loss: 0.7951 - val_acc: 0.7275\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 23s 450us/step - loss: 0.8170 - acc: 0.7148 - val_loss: 0.8002 - val_acc: 0.7262\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 23s 450us/step - loss: 0.8169 - acc: 0.7159 - val_loss: 0.7990 - val_acc: 0.7288\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 0.8158 - acc: 0.7173 - val_loss: 0.7900 - val_acc: 0.7333\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 23s 450us/step - loss: 0.8165 - acc: 0.7168 - val_loss: 0.7930 - val_acc: 0.7312\n",
      "Epoch 51/100\n",
      "40992/50000 [=======================>......] - ETA: 3s - loss: 0.8144 - acc: 0.7163"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "opt_2_lr_dec.fit(x_train, y_train,\n",
    "              batch_size=32,\n",
    "              epochs=100,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 148us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.79080277261734011, 0.73229999999999995]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_2_lr_dec.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decreasing the learning rate, in this case, slows the rate of approach towards the minimum loss drastically. In the first iteration of this neural network, 34 epochs was sufficient to produce a validation accuracy of 77%. However, with a slower learning rate, even after 150 epochs the model is still learning. At each epoch, it makes incredibly small steps. In this case, the amount of compute time is not worth any percieved gain in the models ability to classify. Indeed, it still only scores 73% validation accuracy even after so many epochs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a new rate of decay, and see how that effects the model. Instead of 1e-6, let's try 1e-7. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 23s 455us/step - loss: 1.8259 - acc: 0.3289 - val_loss: 1.5957 - val_acc: 0.4169\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 22s 449us/step - loss: 1.5362 - acc: 0.4436 - val_loss: 1.3743 - val_acc: 0.5005\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 22s 449us/step - loss: 1.3918 - acc: 0.5029 - val_loss: 1.2686 - val_acc: 0.5492\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 22s 449us/step - loss: 1.2888 - acc: 0.5411 - val_loss: 1.1757 - val_acc: 0.5862\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 22s 449us/step - loss: 1.2039 - acc: 0.5743 - val_loss: 1.0885 - val_acc: 0.6157\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 22s 450us/step - loss: 1.1351 - acc: 0.5986 - val_loss: 1.0802 - val_acc: 0.6202\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 22s 449us/step - loss: 1.0778 - acc: 0.6219 - val_loss: 1.0071 - val_acc: 0.6522\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 22s 449us/step - loss: 1.0287 - acc: 0.6391 - val_loss: 0.9911 - val_acc: 0.6527\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 22s 450us/step - loss: 0.9876 - acc: 0.6548 - val_loss: 0.9448 - val_acc: 0.6714\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 23s 458us/step - loss: 0.9554 - acc: 0.6685 - val_loss: 0.9525 - val_acc: 0.6685\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 23s 469us/step - loss: 0.9178 - acc: 0.6809 - val_loss: 0.8576 - val_acc: 0.7052\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 23s 467us/step - loss: 0.8946 - acc: 0.6882 - val_loss: 0.8291 - val_acc: 0.7181\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.8682 - acc: 0.6978 - val_loss: 0.8195 - val_acc: 0.7191\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 23s 467us/step - loss: 0.8450 - acc: 0.7043 - val_loss: 0.8497 - val_acc: 0.7033\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.8285 - acc: 0.7110 - val_loss: 0.7968 - val_acc: 0.7296\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.8146 - acc: 0.7174 - val_loss: 0.7813 - val_acc: 0.7342\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 23s 467us/step - loss: 0.7995 - acc: 0.7255 - val_loss: 0.7791 - val_acc: 0.7379\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.7807 - acc: 0.7292 - val_loss: 0.7604 - val_acc: 0.7425\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.7696 - acc: 0.7347 - val_loss: 0.7510 - val_acc: 0.7452\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.7633 - acc: 0.7345 - val_loss: 0.7644 - val_acc: 0.7425\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.7534 - acc: 0.7409 - val_loss: 0.8061 - val_acc: 0.7342\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 23s 467us/step - loss: 0.7468 - acc: 0.7421 - val_loss: 0.7536 - val_acc: 0.7540\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.7328 - acc: 0.7471 - val_loss: 0.7407 - val_acc: 0.7507\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 23s 467us/step - loss: 0.7368 - acc: 0.7483 - val_loss: 0.7257 - val_acc: 0.7560\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.7279 - acc: 0.7507 - val_loss: 0.7388 - val_acc: 0.7583\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.7261 - acc: 0.7530 - val_loss: 0.7103 - val_acc: 0.7630\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.7162 - acc: 0.7565 - val_loss: 0.6938 - val_acc: 0.7666\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 22s 448us/step - loss: 0.7088 - acc: 0.7592 - val_loss: 0.7132 - val_acc: 0.7551\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 22s 448us/step - loss: 0.7056 - acc: 0.7572 - val_loss: 0.7375 - val_acc: 0.7517\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.7045 - acc: 0.7592 - val_loss: 0.6844 - val_acc: 0.7707\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.7004 - acc: 0.7613 - val_loss: 0.7233 - val_acc: 0.7623\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.6930 - acc: 0.7648 - val_loss: 0.7058 - val_acc: 0.7658\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.6899 - acc: 0.7650 - val_loss: 0.6761 - val_acc: 0.7745\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.6871 - acc: 0.7701 - val_loss: 0.6909 - val_acc: 0.7729\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.6849 - acc: 0.7657 - val_loss: 0.7152 - val_acc: 0.7644\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.6774 - acc: 0.7696 - val_loss: 0.6948 - val_acc: 0.7626\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.6753 - acc: 0.7708 - val_loss: 0.6622 - val_acc: 0.7808\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 23s 454us/step - loss: 0.6728 - acc: 0.7728 - val_loss: 0.6899 - val_acc: 0.7715\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 23s 454us/step - loss: 0.6673 - acc: 0.7731 - val_loss: 0.6621 - val_acc: 0.7764\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.6633 - acc: 0.7762 - val_loss: 0.6838 - val_acc: 0.7695\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.6665 - acc: 0.7749 - val_loss: 0.6818 - val_acc: 0.7732\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.6631 - acc: 0.7762 - val_loss: 0.6691 - val_acc: 0.7818\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.6575 - acc: 0.7786 - val_loss: 0.6750 - val_acc: 0.7825\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 0.6617 - acc: 0.7770 - val_loss: 0.6826 - val_acc: 0.7751\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.6521 - acc: 0.7793 - val_loss: 0.6883 - val_acc: 0.7741\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.6555 - acc: 0.7809 - val_loss: 0.7968 - val_acc: 0.7485\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.6536 - acc: 0.7798 - val_loss: 0.6641 - val_acc: 0.7814\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.6525 - acc: 0.7810 - val_loss: 0.6453 - val_acc: 0.7844\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 23s 454us/step - loss: 0.6527 - acc: 0.7795 - val_loss: 0.6839 - val_acc: 0.7785\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 0.6499 - acc: 0.7831 - val_loss: 0.7128 - val_acc: 0.7795\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.6458 - acc: 0.7821 - val_loss: 0.7669 - val_acc: 0.7605\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 0.6449 - acc: 0.7843 - val_loss: 0.6886 - val_acc: 0.7769\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 23s 454us/step - loss: 0.6453 - acc: 0.7850 - val_loss: 0.6968 - val_acc: 0.7738\n"
     ]
    }
   ],
   "source": [
    "opt_2_dec_inc = standard_network()\n",
    "\n",
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-7)\n",
    "opt_2_dec_inc.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = opt_2_dec_inc.fit(x_train, y_train,\n",
    "              batch_size=32,\n",
    "              epochs=100,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the decay rate appears to offer promising results. The validation accuracy reaches 78% on some epochs before the model's patience (5) is triggered at just above 77%. It also does so in 53 epochs, much better than the lower learning rate from the model previous. \n",
    "\n",
    "Let's try upping the decay rate and see how it effects things. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 23s 458us/step - loss: 1.8500 - acc: 0.3220 - val_loss: 1.5835 - val_acc: 0.4303\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 1.0732 - acc: 0.6244 - val_loss: 0.9990 - val_acc: 0.6513\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 1.0246 - acc: 0.6404 - val_loss: 0.9372 - val_acc: 0.6749\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 23s 450us/step - loss: 0.9825 - acc: 0.6549 - val_loss: 0.9225 - val_acc: 0.6807\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 0.9499 - acc: 0.6692 - val_loss: 0.8799 - val_acc: 0.6957\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 23s 451us/step - loss: 0.9157 - acc: 0.6808 - val_loss: 0.8719 - val_acc: 0.7004\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 23s 450us/step - loss: 0.8872 - acc: 0.6923 - val_loss: 0.8525 - val_acc: 0.7076\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 22s 448us/step - loss: 0.8684 - acc: 0.7013 - val_loss: 0.8148 - val_acc: 0.7176\n",
      "Epoch 14/100\n",
      "42656/50000 [========================>.....] - ETA: 3s - loss: 0.8435 - acc: 0.7064"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 22s 447us/step - loss: 0.7383 - acc: 0.7468 - val_loss: 0.7513 - val_acc: 0.7430\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 22s 446us/step - loss: 0.7310 - acc: 0.7497 - val_loss: 0.7388 - val_acc: 0.7487\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 22s 446us/step - loss: 0.7274 - acc: 0.7514 - val_loss: 0.7168 - val_acc: 0.7527\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 22s 446us/step - loss: 0.7177 - acc: 0.7523 - val_loss: 0.7159 - val_acc: 0.7559\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 22s 446us/step - loss: 0.7138 - acc: 0.7561 - val_loss: 0.6992 - val_acc: 0.7594\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 22s 446us/step - loss: 0.7081 - acc: 0.7595 - val_loss: 0.7737 - val_acc: 0.7407\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 22s 446us/step - loss: 0.7010 - acc: 0.7600 - val_loss: 0.7073 - val_acc: 0.7601\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 22s 446us/step - loss: 0.6989 - acc: 0.7617 - val_loss: 0.6859 - val_acc: 0.7667\n",
      "Epoch 30/100\n",
      "30496/50000 [=================>............] - ETA: 8s - loss: 0.6937 - acc: 0.7606"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 24s 474us/step - loss: 0.6670 - acc: 0.7749 - val_loss: 0.6650 - val_acc: 0.7727\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 23s 468us/step - loss: 0.6642 - acc: 0.7755 - val_loss: 0.6643 - val_acc: 0.7803\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.6601 - acc: 0.7751 - val_loss: 0.6917 - val_acc: 0.7671\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.6627 - acc: 0.7748 - val_loss: 0.6775 - val_acc: 0.7745\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.6614 - acc: 0.7758 - val_loss: 0.6845 - val_acc: 0.7759\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.6621 - acc: 0.7754 - val_loss: 0.6821 - val_acc: 0.7728\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.6537 - acc: 0.7795 - val_loss: 0.6673 - val_acc: 0.7782\n"
     ]
    }
   ],
   "source": [
    "opt_2_dec_dec = standard_network()\n",
    "\n",
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-5)\n",
    "opt_2_dec_dec.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_dec_up = opt_2_dec_dec.fit(x_train, y_train,\n",
    "              batch_size=32,\n",
    "              epochs=100,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the decay to 1e-5 does not seem to help or hinder the model in any drastic way. What if we made a bigger change to the decay?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 23s 460us/step - loss: 2.0745 - acc: 0.2400 - val_loss: 1.9488 - val_acc: 0.3095\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 1.9503 - acc: 0.2909 - val_loss: 1.8843 - val_acc: 0.3351\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 1.9061 - acc: 0.3098 - val_loss: 1.8469 - val_acc: 0.3510\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 1.8779 - acc: 0.3196 - val_loss: 1.8259 - val_acc: 0.3558\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.8592 - acc: 0.3277 - val_loss: 1.8079 - val_acc: 0.3630\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 23s 456us/step - loss: 1.8427 - acc: 0.3318 - val_loss: 1.7942 - val_acc: 0.3675\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 23s 454us/step - loss: 1.8360 - acc: 0.3357 - val_loss: 1.7866 - val_acc: 0.3671\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.8283 - acc: 0.3395 - val_loss: 1.7781 - val_acc: 0.3712\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 1.8210 - acc: 0.3394 - val_loss: 1.7724 - val_acc: 0.3727\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 1.8183 - acc: 0.3434 - val_loss: 1.7674 - val_acc: 0.3738\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 1.8094 - acc: 0.3450 - val_loss: 1.7619 - val_acc: 0.3760\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 23s 455us/step - loss: 1.8065 - acc: 0.3469 - val_loss: 1.7578 - val_acc: 0.3766\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.8026 - acc: 0.3460 - val_loss: 1.7541 - val_acc: 0.3774\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 23s 454us/step - loss: 1.7968 - acc: 0.3499 - val_loss: 1.7504 - val_acc: 0.3790\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 23s 454us/step - loss: 1.7993 - acc: 0.3511 - val_loss: 1.7489 - val_acc: 0.3789\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.7953 - acc: 0.3529 - val_loss: 1.7456 - val_acc: 0.3804\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 23s 454us/step - loss: 1.7900 - acc: 0.3512 - val_loss: 1.7420 - val_acc: 0.3819\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 1.7872 - acc: 0.3543 - val_loss: 1.7400 - val_acc: 0.3826\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.7861 - acc: 0.3538 - val_loss: 1.7372 - val_acc: 0.3844\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.7843 - acc: 0.3554 - val_loss: 1.7354 - val_acc: 0.3838\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.7813 - acc: 0.3542 - val_loss: 1.7330 - val_acc: 0.3861\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 1.7800 - acc: 0.3565 - val_loss: 1.7307 - val_acc: 0.3859\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 1.7775 - acc: 0.3567 - val_loss: 1.7290 - val_acc: 0.3870\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.7753 - acc: 0.3585 - val_loss: 1.7273 - val_acc: 0.3860\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.7728 - acc: 0.3576 - val_loss: 1.7259 - val_acc: 0.3865\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.7739 - acc: 0.3566 - val_loss: 1.7241 - val_acc: 0.3874\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.7723 - acc: 0.3602 - val_loss: 1.7223 - val_acc: 0.3874\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 1.7718 - acc: 0.3591 - val_loss: 1.7208 - val_acc: 0.3887\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 22s 448us/step - loss: 1.7711 - acc: 0.3595 - val_loss: 1.7204 - val_acc: 0.3875\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 22s 446us/step - loss: 1.7665 - acc: 0.3611 - val_loss: 1.7186 - val_acc: 0.3880\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 22s 446us/step - loss: 1.7669 - acc: 0.3622 - val_loss: 1.7172 - val_acc: 0.3892\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 22s 446us/step - loss: 1.7652 - acc: 0.3610 - val_loss: 1.7158 - val_acc: 0.3889\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 22s 446us/step - loss: 1.7658 - acc: 0.3597 - val_loss: 1.7144 - val_acc: 0.3897\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 22s 447us/step - loss: 1.7659 - acc: 0.3631 - val_loss: 1.7136 - val_acc: 0.3886\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 22s 447us/step - loss: 1.7638 - acc: 0.3608 - val_loss: 1.7128 - val_acc: 0.3891\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 22s 447us/step - loss: 1.7596 - acc: 0.3608 - val_loss: 1.7075 - val_acc: 0.3907\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 22s 447us/step - loss: 1.7560 - acc: 0.3635 - val_loss: 1.7065 - val_acc: 0.3919\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 22s 447us/step - loss: 1.7553 - acc: 0.3636 - val_loss: 1.7051 - val_acc: 0.3936\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 22s 448us/step - loss: 1.7535 - acc: 0.3664 - val_loss: 1.7044 - val_acc: 0.3934\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 22s 448us/step - loss: 1.7523 - acc: 0.3647 - val_loss: 1.7033 - val_acc: 0.3940\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 22s 448us/step - loss: 1.7533 - acc: 0.3649 - val_loss: 1.7026 - val_acc: 0.3946\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 22s 448us/step - loss: 1.7531 - acc: 0.3640 - val_loss: 1.7018 - val_acc: 0.3946\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 22s 448us/step - loss: 1.7525 - acc: 0.3660 - val_loss: 1.7008 - val_acc: 0.3956\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 22s 447us/step - loss: 1.7484 - acc: 0.3664 - val_loss: 1.7000 - val_acc: 0.3959\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 22s 447us/step - loss: 1.7502 - acc: 0.3663 - val_loss: 1.6994 - val_acc: 0.3962\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 22s 448us/step - loss: 1.7503 - acc: 0.3676 - val_loss: 1.6987 - val_acc: 0.3966\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 22s 448us/step - loss: 1.7485 - acc: 0.3658 - val_loss: 1.6980 - val_acc: 0.3965\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 22s 448us/step - loss: 1.7471 - acc: 0.3679 - val_loss: 1.6971 - val_acc: 0.3963\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 22s 448us/step - loss: 1.7476 - acc: 0.3673 - val_loss: 1.6965 - val_acc: 0.3968\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 22s 447us/step - loss: 1.7466 - acc: 0.3668 - val_loss: 1.6960 - val_acc: 0.3967\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 22s 448us/step - loss: 1.7461 - acc: 0.3667 - val_loss: 1.6955 - val_acc: 0.3969\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 22s 448us/step - loss: 1.7440 - acc: 0.3667 - val_loss: 1.6946 - val_acc: 0.3972\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 22s 447us/step - loss: 1.7437 - acc: 0.3674 - val_loss: 1.6941 - val_acc: 0.3970\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 22s 447us/step - loss: 1.7425 - acc: 0.3688 - val_loss: 1.6931 - val_acc: 0.3976\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 22s 448us/step - loss: 1.7427 - acc: 0.3691 - val_loss: 1.6925 - val_acc: 0.3973\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 22s 448us/step - loss: 1.7396 - acc: 0.3705 - val_loss: 1.6919 - val_acc: 0.3970\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 22s 448us/step - loss: 1.7409 - acc: 0.3694 - val_loss: 1.6916 - val_acc: 0.3977\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 22s 449us/step - loss: 1.7414 - acc: 0.3688 - val_loss: 1.6907 - val_acc: 0.3971\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 22s 448us/step - loss: 1.7388 - acc: 0.3690 - val_loss: 1.6902 - val_acc: 0.3980\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 22s 449us/step - loss: 1.7423 - acc: 0.3690 - val_loss: 1.6895 - val_acc: 0.3982\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 22s 447us/step - loss: 1.7377 - acc: 0.3700 - val_loss: 1.6889 - val_acc: 0.3982\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 22s 448us/step - loss: 1.7396 - acc: 0.3697 - val_loss: 1.6884 - val_acc: 0.3982\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 22s 448us/step - loss: 1.7405 - acc: 0.3701 - val_loss: 1.6878 - val_acc: 0.3986\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 22s 447us/step - loss: 1.7371 - acc: 0.3723 - val_loss: 1.6872 - val_acc: 0.3989\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 23s 456us/step - loss: 1.7381 - acc: 0.3692 - val_loss: 1.6868 - val_acc: 0.3986\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 23s 467us/step - loss: 1.7357 - acc: 0.3734 - val_loss: 1.6863 - val_acc: 0.3992\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 23s 467us/step - loss: 1.7360 - acc: 0.3734 - val_loss: 1.6857 - val_acc: 0.3992\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 23s 467us/step - loss: 1.7362 - acc: 0.3708 - val_loss: 1.6853 - val_acc: 0.3994\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 1.7370 - acc: 0.3714 - val_loss: 1.6849 - val_acc: 0.4001\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 1.7342 - acc: 0.3706 - val_loss: 1.6844 - val_acc: 0.4001\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 1.7340 - acc: 0.3715 - val_loss: 1.6840 - val_acc: 0.4001\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 1.7346 - acc: 0.3720 - val_loss: 1.6834 - val_acc: 0.4002\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 1.7302 - acc: 0.3721 - val_loss: 1.6828 - val_acc: 0.4003\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 23s 462us/step - loss: 1.7327 - acc: 0.3725 - val_loss: 1.6824 - val_acc: 0.4007\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 22s 449us/step - loss: 1.7327 - acc: 0.3728 - val_loss: 1.6821 - val_acc: 0.4005\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 22s 448us/step - loss: 1.7342 - acc: 0.3718 - val_loss: 1.6816 - val_acc: 0.4003\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 1.7342 - acc: 0.3726 - val_loss: 1.6812 - val_acc: 0.4005\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 23s 454us/step - loss: 1.7309 - acc: 0.3735 - val_loss: 1.6808 - val_acc: 0.4008\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 1.7336 - acc: 0.3709 - val_loss: 1.6803 - val_acc: 0.4010\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 1.7327 - acc: 0.3716 - val_loss: 1.6800 - val_acc: 0.4013\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 1.7311 - acc: 0.3736 - val_loss: 1.6796 - val_acc: 0.4017\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 1.7298 - acc: 0.3748 - val_loss: 1.6791 - val_acc: 0.4018\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 1.7304 - acc: 0.3732 - val_loss: 1.6788 - val_acc: 0.4021\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 1.7294 - acc: 0.3737 - val_loss: 1.6783 - val_acc: 0.4025\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 1.7308 - acc: 0.3712 - val_loss: 1.6780 - val_acc: 0.4027\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.7263 - acc: 0.3734 - val_loss: 1.6775 - val_acc: 0.4030\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 1.7282 - acc: 0.3717 - val_loss: 1.6771 - val_acc: 0.4034\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 23s 458us/step - loss: 1.7294 - acc: 0.3714 - val_loss: 1.6768 - val_acc: 0.4034\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 1.7261 - acc: 0.3767 - val_loss: 1.6764 - val_acc: 0.4035\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 23s 454us/step - loss: 1.7268 - acc: 0.3735 - val_loss: 1.6762 - val_acc: 0.4037\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 1.7269 - acc: 0.3731 - val_loss: 1.6758 - val_acc: 0.4035\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.7238 - acc: 0.3762 - val_loss: 1.6754 - val_acc: 0.4039\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 1.7257 - acc: 0.3746 - val_loss: 1.6750 - val_acc: 0.4037\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 23s 453us/step - loss: 1.7251 - acc: 0.3773 - val_loss: 1.6746 - val_acc: 0.4041\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.7243 - acc: 0.3756 - val_loss: 1.6742 - val_acc: 0.4038\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.7235 - acc: 0.3750 - val_loss: 1.6739 - val_acc: 0.4040\n"
     ]
    }
   ],
   "source": [
    "opt_2_dec_del = standard_network()\n",
    "\n",
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-2)\n",
    "opt_2_dec_del.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_dec_del = opt_2_dec_del.fit(x_train, y_train,\n",
    "              batch_size=32,\n",
    "              epochs=100,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drastically changing the decay towards 1 clearly negatively impacts the networks ability to learn. Even after one hundred epochs, the network barely breaks 40% accuracy. Let's leave decay for now and test different optimization functions themselves. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplist kind of optimizer is Stochastic gradient descent. SGD uses a basic stochastic iteration approach to descend along the gradient with the hope of approaching a minima in the loss function. Here I will implement it with naive properties out of the box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 21s 415us/step - loss: 2.1190 - acc: 0.2106 - val_loss: 1.8657 - val_acc: 0.3396\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 20s 406us/step - loss: 1.7720 - acc: 0.3559 - val_loss: 1.5732 - val_acc: 0.4290\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 20s 406us/step - loss: 1.6037 - acc: 0.4176 - val_loss: 1.6633 - val_acc: 0.4156\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 20s 406us/step - loss: 1.4951 - acc: 0.4553 - val_loss: 1.3675 - val_acc: 0.5114\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 20s 408us/step - loss: 1.4056 - acc: 0.4914 - val_loss: 1.2739 - val_acc: 0.5505\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 20s 407us/step - loss: 1.3319 - acc: 0.5188 - val_loss: 1.2358 - val_acc: 0.5630\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 20s 409us/step - loss: 1.2724 - acc: 0.5428 - val_loss: 1.2073 - val_acc: 0.5687\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 20s 408us/step - loss: 1.2256 - acc: 0.5620 - val_loss: 1.1461 - val_acc: 0.5909\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 20s 406us/step - loss: 1.1783 - acc: 0.5790 - val_loss: 1.0831 - val_acc: 0.6159\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 20s 406us/step - loss: 1.1308 - acc: 0.5958 - val_loss: 1.0810 - val_acc: 0.6168\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 20s 406us/step - loss: 1.0938 - acc: 0.6125 - val_loss: 0.9978 - val_acc: 0.6503\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 20s 406us/step - loss: 1.0561 - acc: 0.6224 - val_loss: 0.9622 - val_acc: 0.6608\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 20s 406us/step - loss: 1.0263 - acc: 0.6359 - val_loss: 0.9459 - val_acc: 0.6665\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 20s 408us/step - loss: 0.9890 - acc: 0.6494 - val_loss: 0.9094 - val_acc: 0.6829\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 20s 407us/step - loss: 0.9594 - acc: 0.6612 - val_loss: 0.9155 - val_acc: 0.6832\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 20s 408us/step - loss: 0.9350 - acc: 0.6695 - val_loss: 0.8862 - val_acc: 0.6911\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 20s 410us/step - loss: 0.9038 - acc: 0.6794 - val_loss: 0.8500 - val_acc: 0.7069\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 20s 410us/step - loss: 0.8778 - acc: 0.6888 - val_loss: 0.8457 - val_acc: 0.7029\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 20s 409us/step - loss: 0.8535 - acc: 0.7009 - val_loss: 0.7885 - val_acc: 0.7273\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 20s 400us/step - loss: 0.8346 - acc: 0.7045 - val_loss: 0.7946 - val_acc: 0.7250\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 20s 401us/step - loss: 0.8090 - acc: 0.7143 - val_loss: 0.8390 - val_acc: 0.7050\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 20s 402us/step - loss: 0.7895 - acc: 0.7208 - val_loss: 0.7398 - val_acc: 0.7410\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 20s 406us/step - loss: 0.7730 - acc: 0.7275 - val_loss: 0.7456 - val_acc: 0.7395\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 20s 402us/step - loss: 0.7515 - acc: 0.7354 - val_loss: 0.7463 - val_acc: 0.7387\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 20s 402us/step - loss: 0.7322 - acc: 0.7429 - val_loss: 0.7133 - val_acc: 0.7535\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 20s 401us/step - loss: 0.7145 - acc: 0.7501 - val_loss: 0.6976 - val_acc: 0.7588\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 20s 401us/step - loss: 0.6980 - acc: 0.7550 - val_loss: 0.7109 - val_acc: 0.7522\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 20s 401us/step - loss: 0.6853 - acc: 0.7581 - val_loss: 0.7128 - val_acc: 0.7491\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 20s 402us/step - loss: 0.6712 - acc: 0.7634 - val_loss: 0.6811 - val_acc: 0.7623\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 20s 402us/step - loss: 0.6573 - acc: 0.7668 - val_loss: 0.6831 - val_acc: 0.7644\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 20s 402us/step - loss: 0.6387 - acc: 0.7743 - val_loss: 0.7024 - val_acc: 0.7556\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 20s 401us/step - loss: 0.6312 - acc: 0.7772 - val_loss: 0.6729 - val_acc: 0.7687\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 20s 401us/step - loss: 0.6154 - acc: 0.7834 - val_loss: 0.6610 - val_acc: 0.7733\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 20s 400us/step - loss: 0.6023 - acc: 0.7882 - val_loss: 0.6495 - val_acc: 0.7723\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 20s 400us/step - loss: 0.5868 - acc: 0.7920 - val_loss: 0.6567 - val_acc: 0.7723\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 20s 400us/step - loss: 0.5735 - acc: 0.7978 - val_loss: 0.6589 - val_acc: 0.7689\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 20s 400us/step - loss: 0.5646 - acc: 0.7989 - val_loss: 0.6364 - val_acc: 0.7790\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 20s 400us/step - loss: 0.5502 - acc: 0.8048 - val_loss: 0.6220 - val_acc: 0.7865\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 20s 400us/step - loss: 0.5456 - acc: 0.8063 - val_loss: 0.6316 - val_acc: 0.7788\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 20s 400us/step - loss: 0.5336 - acc: 0.8122 - val_loss: 0.6337 - val_acc: 0.7810\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 20s 400us/step - loss: 0.5210 - acc: 0.8146 - val_loss: 0.6306 - val_acc: 0.7862\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 20s 401us/step - loss: 0.5172 - acc: 0.8170 - val_loss: 0.6427 - val_acc: 0.7781\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 20s 401us/step - loss: 0.5049 - acc: 0.8201 - val_loss: 0.6082 - val_acc: 0.7918\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 20s 401us/step - loss: 0.4998 - acc: 0.8209 - val_loss: 0.6503 - val_acc: 0.7824\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 20s 401us/step - loss: 0.4820 - acc: 0.8288 - val_loss: 0.6077 - val_acc: 0.7938\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 20s 400us/step - loss: 0.4707 - acc: 0.8339 - val_loss: 0.6115 - val_acc: 0.7911\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 20s 400us/step - loss: 0.4683 - acc: 0.8326 - val_loss: 0.6033 - val_acc: 0.7952\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 20s 401us/step - loss: 0.4557 - acc: 0.8376 - val_loss: 0.6021 - val_acc: 0.7983\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 20s 402us/step - loss: 0.4055 - acc: 0.8542 - val_loss: 0.5996 - val_acc: 0.8028\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 20s 401us/step - loss: 0.3958 - acc: 0.8590 - val_loss: 0.5957 - val_acc: 0.7994\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 20s 399us/step - loss: 0.3903 - acc: 0.8599 - val_loss: 0.6065 - val_acc: 0.7980\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 20s 399us/step - loss: 0.3831 - acc: 0.8618 - val_loss: 0.5969 - val_acc: 0.8040\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 20s 400us/step - loss: 0.3757 - acc: 0.8640 - val_loss: 0.6069 - val_acc: 0.8006\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 20s 401us/step - loss: 0.3654 - acc: 0.8696 - val_loss: 0.6037 - val_acc: 0.8017\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 20s 400us/step - loss: 0.3627 - acc: 0.8693 - val_loss: 0.5970 - val_acc: 0.8000\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 20s 402us/step - loss: 0.3552 - acc: 0.8724 - val_loss: 0.6326 - val_acc: 0.7902\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 20s 401us/step - loss: 0.3522 - acc: 0.8733 - val_loss: 0.6040 - val_acc: 0.8046\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 20s 400us/step - loss: 0.3465 - acc: 0.8753 - val_loss: 0.6069 - val_acc: 0.8005\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 20s 401us/step - loss: 0.3327 - acc: 0.8784 - val_loss: 0.6056 - val_acc: 0.8057\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 20s 401us/step - loss: 0.3320 - acc: 0.8813 - val_loss: 0.6181 - val_acc: 0.7985\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 20s 404us/step - loss: 0.3293 - acc: 0.8810 - val_loss: 0.6619 - val_acc: 0.7945\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 20s 401us/step - loss: 0.3244 - acc: 0.8823 - val_loss: 0.6053 - val_acc: 0.8040\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 20s 402us/step - loss: 0.3155 - acc: 0.8861 - val_loss: 0.6133 - val_acc: 0.8079\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 20s 400us/step - loss: 0.3110 - acc: 0.8903 - val_loss: 0.6075 - val_acc: 0.8086\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 20s 401us/step - loss: 0.3058 - acc: 0.8903 - val_loss: 0.6182 - val_acc: 0.8044\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 20s 401us/step - loss: 0.3056 - acc: 0.8894 - val_loss: 0.5995 - val_acc: 0.8081\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 20s 402us/step - loss: 0.2972 - acc: 0.8920 - val_loss: 0.6127 - val_acc: 0.8060\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 20s 403us/step - loss: 0.2939 - acc: 0.8938 - val_loss: 0.6156 - val_acc: 0.8080\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 20s 402us/step - loss: 0.2869 - acc: 0.8977 - val_loss: 0.6211 - val_acc: 0.8075\n"
     ]
    }
   ],
   "source": [
    "opt_3_sgd = standard_network()\n",
    "\n",
    "opt = keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
    "opt_3_sgd.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_sgd = opt_3_sgd.fit(x_train, y_train,\n",
    "              batch_size=32,\n",
    "              epochs=100,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard SGD actually does really well at learning the model. We do notice some overfitting happening, but in 75 epochs the network reaches 80% validation accuracy. Let's check against the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 145us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.62109199433326723, 0.8075]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_3_sgd.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try out some different hyperparameters here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 21s 411us/step - loss: 2.1197 - acc: 0.2118 - val_loss: 1.8400 - val_acc: 0.3505\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 20s 404us/step - loss: 1.7505 - acc: 0.3624 - val_loss: 1.6534 - val_acc: 0.4088\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 20s 402us/step - loss: 1.5492 - acc: 0.4365 - val_loss: 1.3818 - val_acc: 0.4998\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 20s 404us/step - loss: 1.4248 - acc: 0.4851 - val_loss: 1.3890 - val_acc: 0.4927\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 20s 403us/step - loss: 1.3375 - acc: 0.5167 - val_loss: 1.2110 - val_acc: 0.5651\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 20s 402us/step - loss: 1.2629 - acc: 0.5482 - val_loss: 1.1765 - val_acc: 0.5788\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 20s 403us/step - loss: 1.1972 - acc: 0.5759 - val_loss: 1.1082 - val_acc: 0.6104\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 20s 402us/step - loss: 1.1390 - acc: 0.5941 - val_loss: 1.0297 - val_acc: 0.6334\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 20s 407us/step - loss: 1.0911 - acc: 0.6136 - val_loss: 0.9864 - val_acc: 0.6511\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 20s 403us/step - loss: 1.0424 - acc: 0.6291 - val_loss: 0.9486 - val_acc: 0.6659\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 20s 403us/step - loss: 1.0018 - acc: 0.6456 - val_loss: 0.9372 - val_acc: 0.6737\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 20s 403us/step - loss: 0.9626 - acc: 0.6583 - val_loss: 0.9178 - val_acc: 0.6816\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 20s 403us/step - loss: 0.9319 - acc: 0.6707 - val_loss: 0.9084 - val_acc: 0.6802\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 20s 403us/step - loss: 0.8992 - acc: 0.6845 - val_loss: 0.9070 - val_acc: 0.6796\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 20s 403us/step - loss: 0.8759 - acc: 0.6922 - val_loss: 0.8326 - val_acc: 0.7065\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 20s 404us/step - loss: 0.8494 - acc: 0.7004 - val_loss: 0.8058 - val_acc: 0.7188\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 20s 402us/step - loss: 0.8198 - acc: 0.7101 - val_loss: 0.8026 - val_acc: 0.7227\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 20s 408us/step - loss: 0.7983 - acc: 0.7203 - val_loss: 0.7497 - val_acc: 0.7414\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 21s 422us/step - loss: 0.7781 - acc: 0.7263 - val_loss: 0.7425 - val_acc: 0.7438\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 21s 423us/step - loss: 0.7607 - acc: 0.7321 - val_loss: 0.7373 - val_acc: 0.7416\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 21s 423us/step - loss: 0.7364 - acc: 0.7389 - val_loss: 0.7250 - val_acc: 0.7475\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 21s 423us/step - loss: 0.7188 - acc: 0.7453 - val_loss: 0.7058 - val_acc: 0.7571\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 21s 423us/step - loss: 0.6945 - acc: 0.7558 - val_loss: 0.6855 - val_acc: 0.7627\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 21s 421us/step - loss: 0.6852 - acc: 0.7575 - val_loss: 0.6710 - val_acc: 0.7677\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 21s 422us/step - loss: 0.6713 - acc: 0.7639 - val_loss: 0.6870 - val_acc: 0.7667\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 21s 421us/step - loss: 0.6519 - acc: 0.7709 - val_loss: 0.6881 - val_acc: 0.7649\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 20s 407us/step - loss: 0.6400 - acc: 0.7740 - val_loss: 0.6656 - val_acc: 0.7688\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 20s 403us/step - loss: 0.6242 - acc: 0.7790 - val_loss: 0.6591 - val_acc: 0.7703\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 20s 406us/step - loss: 0.6135 - acc: 0.7832 - val_loss: 0.6451 - val_acc: 0.7785\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 20s 407us/step - loss: 0.5986 - acc: 0.7896 - val_loss: 0.6468 - val_acc: 0.7763\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 20s 407us/step - loss: 0.5861 - acc: 0.7913 - val_loss: 0.6497 - val_acc: 0.7735\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 20s 407us/step - loss: 0.5784 - acc: 0.7932 - val_loss: 0.6315 - val_acc: 0.7870\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 20s 407us/step - loss: 0.5622 - acc: 0.8013 - val_loss: 0.6638 - val_acc: 0.7743\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 20s 409us/step - loss: 0.5521 - acc: 0.8060 - val_loss: 0.6419 - val_acc: 0.7771\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 20s 407us/step - loss: 0.5396 - acc: 0.8093 - val_loss: 0.6199 - val_acc: 0.7852\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 20s 409us/step - loss: 0.5285 - acc: 0.8116 - val_loss: 0.6173 - val_acc: 0.7904\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 20s 410us/step - loss: 0.5206 - acc: 0.8150 - val_loss: 0.6177 - val_acc: 0.7885\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 21s 411us/step - loss: 0.5037 - acc: 0.8207 - val_loss: 0.6093 - val_acc: 0.7891\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 21s 412us/step - loss: 0.4942 - acc: 0.8240 - val_loss: 0.6002 - val_acc: 0.7943\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 20s 408us/step - loss: 0.4848 - acc: 0.8271 - val_loss: 0.6282 - val_acc: 0.7886\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 20s 408us/step - loss: 0.4750 - acc: 0.8319 - val_loss: 0.6241 - val_acc: 0.7880\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 20s 410us/step - loss: 0.4663 - acc: 0.8329 - val_loss: 0.6077 - val_acc: 0.7923\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 20s 408us/step - loss: 0.4590 - acc: 0.8344 - val_loss: 0.6281 - val_acc: 0.7891\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 20s 410us/step - loss: 0.4425 - acc: 0.8409 - val_loss: 0.6083 - val_acc: 0.7972\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 21s 411us/step - loss: 0.4390 - acc: 0.8437 - val_loss: 0.5951 - val_acc: 0.8016\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 20s 409us/step - loss: 0.4304 - acc: 0.8452 - val_loss: 0.6189 - val_acc: 0.7905\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 20s 408us/step - loss: 0.4238 - acc: 0.8493 - val_loss: 0.5863 - val_acc: 0.8012\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 20s 408us/step - loss: 0.4142 - acc: 0.8523 - val_loss: 0.5897 - val_acc: 0.7990\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 20s 409us/step - loss: 0.4106 - acc: 0.8527 - val_loss: 0.6024 - val_acc: 0.7996\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 20s 408us/step - loss: 0.4028 - acc: 0.8547 - val_loss: 0.5964 - val_acc: 0.7975\n"
     ]
    }
   ],
   "source": [
    "opt_3_sgd_mo = standard_network()\n",
    "\n",
    "opt = keras.optimizers.SGD(lr=0.01, momentum=0.1, decay=0.0, nesterov=False)\n",
    "opt_3_sgd_mo.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_sgd_mo = opt_3_sgd_mo.fit(x_train, y_train,\n",
    "              batch_size=32,\n",
    "              epochs=100,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 147us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.59636540532112126, 0.79749999999999999]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_3_sgd_mo.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 21s 430us/step - loss: 2.0330 - acc: 0.2446 - val_loss: 1.8968 - val_acc: 0.3264\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 21s 422us/step - loss: 1.6508 - acc: 0.3978 - val_loss: 1.4227 - val_acc: 0.4806\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 21s 420us/step - loss: 1.4397 - acc: 0.4769 - val_loss: 1.3150 - val_acc: 0.5312\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 21s 422us/step - loss: 1.3139 - acc: 0.5278 - val_loss: 1.1853 - val_acc: 0.5837\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 21s 422us/step - loss: 1.2191 - acc: 0.5642 - val_loss: 1.1138 - val_acc: 0.6025\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 21s 420us/step - loss: 1.1419 - acc: 0.5937 - val_loss: 1.0585 - val_acc: 0.6305\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 21s 423us/step - loss: 1.0666 - acc: 0.6188 - val_loss: 0.9980 - val_acc: 0.6485\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 21s 414us/step - loss: 1.0074 - acc: 0.6453 - val_loss: 0.9057 - val_acc: 0.6808\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 21s 414us/step - loss: 0.9515 - acc: 0.6618 - val_loss: 0.8592 - val_acc: 0.7010\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 21s 414us/step - loss: 0.9062 - acc: 0.6799 - val_loss: 0.8411 - val_acc: 0.7019\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 21s 414us/step - loss: 0.8670 - acc: 0.6952 - val_loss: 0.7978 - val_acc: 0.7243\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 21s 415us/step - loss: 0.8230 - acc: 0.7102 - val_loss: 0.7836 - val_acc: 0.7272\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 21s 416us/step - loss: 0.7896 - acc: 0.7222 - val_loss: 0.7418 - val_acc: 0.7402\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 21s 416us/step - loss: 0.7616 - acc: 0.7307 - val_loss: 0.7228 - val_acc: 0.7492\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 21s 415us/step - loss: 0.7358 - acc: 0.7415 - val_loss: 0.7550 - val_acc: 0.7368\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 21s 416us/step - loss: 0.7141 - acc: 0.7469 - val_loss: 0.6875 - val_acc: 0.7657\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 21s 418us/step - loss: 0.6806 - acc: 0.7608 - val_loss: 0.6746 - val_acc: 0.7711\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 21s 418us/step - loss: 0.6610 - acc: 0.7661 - val_loss: 0.6748 - val_acc: 0.7604\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 21s 415us/step - loss: 0.6430 - acc: 0.7731 - val_loss: 0.6545 - val_acc: 0.7717\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 21s 418us/step - loss: 0.6238 - acc: 0.7794 - val_loss: 0.6443 - val_acc: 0.7750\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 21s 415us/step - loss: 0.6026 - acc: 0.7891 - val_loss: 0.6413 - val_acc: 0.7778\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 21s 418us/step - loss: 0.5838 - acc: 0.7926 - val_loss: 0.6519 - val_acc: 0.7744\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 21s 415us/step - loss: 0.5683 - acc: 0.7982 - val_loss: 0.7564 - val_acc: 0.7480\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 21s 416us/step - loss: 0.5562 - acc: 0.8020 - val_loss: 0.6399 - val_acc: 0.7774\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 21s 416us/step - loss: 0.5419 - acc: 0.8068 - val_loss: 0.6238 - val_acc: 0.7835\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 21s 415us/step - loss: 0.5220 - acc: 0.8126 - val_loss: 0.6435 - val_acc: 0.7844\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 21s 415us/step - loss: 0.5125 - acc: 0.8184 - val_loss: 0.6215 - val_acc: 0.7879\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 21s 416us/step - loss: 0.4889 - acc: 0.8250 - val_loss: 0.6359 - val_acc: 0.7830\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 21s 414us/step - loss: 0.4864 - acc: 0.8267 - val_loss: 0.6122 - val_acc: 0.7896\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 21s 414us/step - loss: 0.4726 - acc: 0.8312 - val_loss: 0.5967 - val_acc: 0.7940\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 21s 415us/step - loss: 0.4583 - acc: 0.8373 - val_loss: 0.5999 - val_acc: 0.7937\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 21s 414us/step - loss: 0.4436 - acc: 0.8434 - val_loss: 0.6030 - val_acc: 0.7938\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 21s 414us/step - loss: 0.4322 - acc: 0.8457 - val_loss: 0.5963 - val_acc: 0.7964\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 21s 416us/step - loss: 0.4275 - acc: 0.8480 - val_loss: 0.6233 - val_acc: 0.7894\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 21s 414us/step - loss: 0.4129 - acc: 0.8511 - val_loss: 0.5932 - val_acc: 0.8000\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 21s 414us/step - loss: 0.4038 - acc: 0.8541 - val_loss: 0.6164 - val_acc: 0.7949\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 21s 415us/step - loss: 0.3973 - acc: 0.8589 - val_loss: 0.5921 - val_acc: 0.7996\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 21s 414us/step - loss: 0.3876 - acc: 0.8626 - val_loss: 0.6100 - val_acc: 0.7956\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 21s 414us/step - loss: 0.3756 - acc: 0.8645 - val_loss: 0.6076 - val_acc: 0.8012\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 21s 415us/step - loss: 0.3674 - acc: 0.8693 - val_loss: 0.6302 - val_acc: 0.7949\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 21s 414us/step - loss: 0.3616 - acc: 0.8707 - val_loss: 0.6105 - val_acc: 0.7997\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 21s 415us/step - loss: 0.3550 - acc: 0.8732 - val_loss: 0.6085 - val_acc: 0.8022\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 21s 417us/step - loss: 0.3453 - acc: 0.8774 - val_loss: 0.6150 - val_acc: 0.8019\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 21s 415us/step - loss: 0.3415 - acc: 0.8780 - val_loss: 0.6146 - val_acc: 0.7999\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 21s 415us/step - loss: 0.3301 - acc: 0.8807 - val_loss: 0.5996 - val_acc: 0.8056\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 21s 415us/step - loss: 0.3270 - acc: 0.8813 - val_loss: 0.6052 - val_acc: 0.8071\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 21s 415us/step - loss: 0.3170 - acc: 0.8876 - val_loss: 0.5979 - val_acc: 0.8041\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 21s 416us/step - loss: 0.3114 - acc: 0.8874 - val_loss: 0.6367 - val_acc: 0.8007\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 21s 415us/step - loss: 0.3073 - acc: 0.8896 - val_loss: 0.6886 - val_acc: 0.7916\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 21s 415us/step - loss: 0.3027 - acc: 0.8928 - val_loss: 0.6085 - val_acc: 0.8030\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 21s 415us/step - loss: 0.2989 - acc: 0.8937 - val_loss: 0.6231 - val_acc: 0.8020\n"
     ]
    }
   ],
   "source": [
    "opt_3_sgd_nes = standard_network()\n",
    "\n",
    "opt = keras.optimizers.SGD(lr=0.01, momentum=0.5, decay=0.0, nesterov=True)\n",
    "opt_3_sgd_nes.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_sgd_nes = opt_3_sgd_nes.fit(x_train, y_train,\n",
    "              batch_size=32,\n",
    "              epochs=100,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80200000000000005"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_sgd_nes.history['val_acc'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 147us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.62306540794372556, 0.80200000000000005]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_3_sgd_nes.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that using the nesterov momentum and slightly upping momentum itself provides slightly better results in 50 epochs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try Adam "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_29 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 24s 488us/step - loss: 1.5449 - acc: 0.4378 - val_loss: 1.2216 - val_acc: 0.5559\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 24s 477us/step - loss: 1.1457 - acc: 0.5933 - val_loss: 0.9813 - val_acc: 0.6594\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 24s 479us/step - loss: 0.9790 - acc: 0.6561 - val_loss: 0.8615 - val_acc: 0.7011\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 24s 481us/step - loss: 0.8718 - acc: 0.6958 - val_loss: 0.7775 - val_acc: 0.7297\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 24s 476us/step - loss: 0.8020 - acc: 0.7194 - val_loss: 0.7511 - val_acc: 0.7420\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 24s 473us/step - loss: 0.7554 - acc: 0.7361 - val_loss: 0.7230 - val_acc: 0.7516\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 24s 472us/step - loss: 0.7202 - acc: 0.7475 - val_loss: 0.6831 - val_acc: 0.7639\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 24s 475us/step - loss: 0.6811 - acc: 0.7614 - val_loss: 0.6714 - val_acc: 0.7667\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 24s 474us/step - loss: 0.6542 - acc: 0.7702 - val_loss: 0.6805 - val_acc: 0.7673\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 24s 473us/step - loss: 0.6356 - acc: 0.7766 - val_loss: 0.6889 - val_acc: 0.7667\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 24s 473us/step - loss: 0.5526 - acc: 0.8063 - val_loss: 0.6644 - val_acc: 0.7806\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 24s 473us/step - loss: 0.5371 - acc: 0.8107 - val_loss: 0.6510 - val_acc: 0.7822\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 24s 482us/step - loss: 0.5186 - acc: 0.8189 - val_loss: 0.6661 - val_acc: 0.7786\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 25s 493us/step - loss: 0.5128 - acc: 0.8193 - val_loss: 0.6558 - val_acc: 0.7878\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 25s 494us/step - loss: 0.5029 - acc: 0.8218 - val_loss: 0.6502 - val_acc: 0.7916\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 25s 493us/step - loss: 0.4925 - acc: 0.8257 - val_loss: 0.6453 - val_acc: 0.7925\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 25s 493us/step - loss: 0.4893 - acc: 0.8273 - val_loss: 0.6339 - val_acc: 0.7933\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 25s 495us/step - loss: 0.4789 - acc: 0.8318 - val_loss: 0.6569 - val_acc: 0.7884\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 25s 494us/step - loss: 0.4651 - acc: 0.8376 - val_loss: 0.6775 - val_acc: 0.7870\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 25s 493us/step - loss: 0.4621 - acc: 0.8378 - val_loss: 0.6557 - val_acc: 0.7956\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 25s 493us/step - loss: 0.4601 - acc: 0.8396 - val_loss: 0.6820 - val_acc: 0.7806\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 25s 492us/step - loss: 0.4414 - acc: 0.8448 - val_loss: 0.6486 - val_acc: 0.7939\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 25s 493us/step - loss: 0.4484 - acc: 0.8425 - val_loss: 0.6379 - val_acc: 0.7942\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 25s 493us/step - loss: 0.4330 - acc: 0.8489 - val_loss: 0.6711 - val_acc: 0.7859\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 25s 493us/step - loss: 0.4378 - acc: 0.8488 - val_loss: 0.6655 - val_acc: 0.7897\n"
     ]
    }
   ],
   "source": [
    "opt_3_adam = standard_network()\n",
    "\n",
    "opt = keras.optimizers.adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "opt_3_adam.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_adam = opt_3_adam.fit(x_train, y_train,\n",
    "              batch_size=32,\n",
    "              epochs=100,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 25s 492us/step - loss: 0.3348 - acc: 0.8813 - val_loss: 0.6462 - val_acc: 0.8044\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 24s 479us/step - loss: 0.3134 - acc: 0.8894 - val_loss: 0.6466 - val_acc: 0.8060\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 24s 479us/step - loss: 0.2987 - acc: 0.8942 - val_loss: 0.6449 - val_acc: 0.8062\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 24s 480us/step - loss: 0.2834 - acc: 0.9004 - val_loss: 0.6372 - val_acc: 0.8109\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 24s 481us/step - loss: 0.2799 - acc: 0.9010 - val_loss: 0.6522 - val_acc: 0.8084\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 24s 482us/step - loss: 0.2757 - acc: 0.9033 - val_loss: 0.6469 - val_acc: 0.8081\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 24s 488us/step - loss: 0.2662 - acc: 0.9050 - val_loss: 0.6525 - val_acc: 0.8084\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 24s 487us/step - loss: 0.2665 - acc: 0.9052 - val_loss: 0.6533 - val_acc: 0.8106\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 24s 488us/step - loss: 0.2645 - acc: 0.9049 - val_loss: 0.6421 - val_acc: 0.8121\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 24s 486us/step - loss: 0.2580 - acc: 0.9077 - val_loss: 0.6442 - val_acc: 0.8125\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 24s 487us/step - loss: 0.2520 - acc: 0.9095 - val_loss: 0.6472 - val_acc: 0.8131\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 24s 481us/step - loss: 0.2511 - acc: 0.9107 - val_loss: 0.6603 - val_acc: 0.8112\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 24s 481us/step - loss: 0.2518 - acc: 0.9107 - val_loss: 0.6526 - val_acc: 0.8131\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 24s 481us/step - loss: 0.2438 - acc: 0.9120 - val_loss: 0.6526 - val_acc: 0.8167\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 24s 479us/step - loss: 0.2401 - acc: 0.9135 - val_loss: 0.6510 - val_acc: 0.8150\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 24s 481us/step - loss: 0.2401 - acc: 0.9141 - val_loss: 0.6634 - val_acc: 0.8133\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 24s 483us/step - loss: 0.2334 - acc: 0.9163 - val_loss: 0.6671 - val_acc: 0.8111\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 24s 480us/step - loss: 0.2311 - acc: 0.9179 - val_loss: 0.6496 - val_acc: 0.8163\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 24s 481us/step - loss: 0.2330 - acc: 0.9176 - val_loss: 0.6489 - val_acc: 0.8158\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "opt_3_adam.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_adam = opt_3_adam.fit(x_train, y_train,\n",
    "              batch_size=32,\n",
    "              epochs=100,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 25s 493us/step - loss: 0.2232 - acc: 0.9202 - val_loss: 0.6620 - val_acc: 0.8145\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 25s 494us/step - loss: 0.2246 - acc: 0.9198 - val_loss: 0.6602 - val_acc: 0.8140\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 25s 496us/step - loss: 0.2181 - acc: 0.9216 - val_loss: 0.6636 - val_acc: 0.8150\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 25s 495us/step - loss: 0.2197 - acc: 0.9218 - val_loss: 0.6616 - val_acc: 0.8148\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 24s 484us/step - loss: 0.2257 - acc: 0.9173 - val_loss: 0.6612 - val_acc: 0.8153\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 24s 486us/step - loss: 0.2179 - acc: 0.9222 - val_loss: 0.6618 - val_acc: 0.8155\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 24s 486us/step - loss: 0.2194 - acc: 0.9208 - val_loss: 0.6609 - val_acc: 0.8165\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 24s 481us/step - loss: 0.2187 - acc: 0.9220 - val_loss: 0.6604 - val_acc: 0.8165\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 24s 486us/step - loss: 0.2185 - acc: 0.9210 - val_loss: 0.6619 - val_acc: 0.8161\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 24s 485us/step - loss: 0.2209 - acc: 0.9221 - val_loss: 0.6652 - val_acc: 0.8159\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 24s 482us/step - loss: 0.2208 - acc: 0.9220 - val_loss: 0.6615 - val_acc: 0.8165\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 24s 483us/step - loss: 0.2171 - acc: 0.9228 - val_loss: 0.6635 - val_acc: 0.8150\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.adam(lr=0.00001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "opt_3_adam.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_adam = opt_3_adam.fit(x_train, y_train,\n",
    "              batch_size=32,\n",
    "              epochs=100,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same model can be recompiled and given adjusted learning rates. By starting with a relatively faster learning rate, one can approach a good approximation of the minimum on the first series of passes. Next, adjusting the learning rate down can fine tune the model if small percentage gains are desired. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 145us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.66349807536602023, 0.81499999999999995]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_3_adam.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we were able to produce a model that tests at 81.5% accuracy. To perserve computing time and power, let's save this model and move on to adding data augmentation in the next notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_3_adam.save('60_epoch_adam.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
