{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproducing LeNet and AlexNet in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous notebooks, I have reproduced example CNN's and simple feed forward NN's on the CIFAR-10 images in Keras. In this notebook, my goal will be to build CNN's with the structure of historically groundbreaking convulutional neural networks. \n",
    "\n",
    "The first historical CNN I will reproduce here will have the structure of LeNet:\n",
    "\n",
    "    INPUT => CONV => RELU => POOL => CONV => RELU => POOL => FC => RELU => FC\n",
    "    \n",
    "The second will be AlexNet, the winner of the 2012 ImageNet Large-Scale Visual Recognition Challenge:\n",
    "    \n",
    "    INPUT => CONV => RELU => POOL => CONV => RELU => POOL => CONV => RELU => CONV => RELU => CONV => RELU => FC => RELU => FC => RELU => FC => SOFTMAX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will also implement TensorBoard functionality in this notebook and use it to track my model performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeNet's structure has existed since 1998, years before CNN's achieved state-of-the-art status recognition in image classification. \n",
    "\n",
    "The disparity between the length of time CNN's have existed and how long they have been recognized as state-of-the-art stems from the availability of processing power to actually put the theoretical frameworks to work and begin building deep, complex structures. LeNet, which was functional as early as 1998, simply was not deep enough to be considered state-of-the-art compared to other methods of image classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "%run __initremote__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_acc', \n",
    "                                           min_delta=0, \n",
    "                                           patience=5, \n",
    "                                           verbose=0, \n",
    "                                           mode='auto')\n",
    "\n",
    "tb = TensorBoard(log_dir='./logs/', embeddings_layer_names='emb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3), padding='same', input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_27 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 512)               1606144   \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,630,666\n",
      "Trainable params: 1,630,666\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 15s 297us/step - loss: 1.6445 - acc: 0.4145 - val_loss: 1.4115 - val_acc: 0.5013\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 15s 292us/step - loss: 1.3319 - acc: 0.5305 - val_loss: 1.2898 - val_acc: 0.5387\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 15s 294us/step - loss: 1.2024 - acc: 0.5794 - val_loss: 1.2235 - val_acc: 0.5741\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 15s 292us/step - loss: 1.1129 - acc: 0.6123 - val_loss: 1.0929 - val_acc: 0.6196\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 15s 292us/step - loss: 1.0420 - acc: 0.6381 - val_loss: 1.0808 - val_acc: 0.6209\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 15s 293us/step - loss: 0.9866 - acc: 0.6583 - val_loss: 1.0000 - val_acc: 0.6531\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 15s 293us/step - loss: 0.9398 - acc: 0.6747 - val_loss: 1.0446 - val_acc: 0.6389\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 15s 295us/step - loss: 0.8960 - acc: 0.6913 - val_loss: 0.9635 - val_acc: 0.6668\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 15s 293us/step - loss: 0.8582 - acc: 0.7034 - val_loss: 0.9486 - val_acc: 0.6702\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 15s 291us/step - loss: 0.8211 - acc: 0.7169 - val_loss: 0.9138 - val_acc: 0.6870\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 15s 293us/step - loss: 0.5379 - acc: 0.8187 - val_loss: 0.8592 - val_acc: 0.7108\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 15s 291us/step - loss: 0.5085 - acc: 0.8291 - val_loss: 0.8486 - val_acc: 0.7200\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 15s 293us/step - loss: 0.4799 - acc: 0.8378 - val_loss: 0.8689 - val_acc: 0.7160\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 15s 291us/step - loss: 0.4524 - acc: 0.8502 - val_loss: 0.9055 - val_acc: 0.7060\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 14s 290us/step - loss: 0.4250 - acc: 0.8589 - val_loss: 0.9885 - val_acc: 0.6948\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 15s 291us/step - loss: 0.3984 - acc: 0.8687 - val_loss: 0.9142 - val_acc: 0.7150\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 15s 292us/step - loss: 0.3718 - acc: 0.8780 - val_loss: 1.0065 - val_acc: 0.6979\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 15s 291us/step - loss: 0.3467 - acc: 0.8880 - val_loss: 0.9501 - val_acc: 0.7082\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 15s 292us/step - loss: 0.3230 - acc: 0.8966 - val_loss: 0.9098 - val_acc: 0.7160\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 15s 291us/step - loss: 0.2982 - acc: 0.9070 - val_loss: 0.9245 - val_acc: 0.7223\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 15s 290us/step - loss: 0.2746 - acc: 0.9141 - val_loss: 0.9476 - val_acc: 0.7174\n",
      "Epoch 30/100\n",
      "35168/50000 [====================>.........] - ETA: 4s - loss: 0.2462 - acc: 0.9239"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lenet_hist = model.fit(x_train, y_train,\n",
    "              batch_size=32,\n",
    "              epochs=100,\n",
    "              validation_data=(x_test, y_test),\n",
    "              callbacks=[early_stop, tb],\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 113us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3201976045608521, 0.69359999999999999]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of today's Neural Network architectures, LeNet appears ancient. It lacks layers such as Dropout and Normalization that aid in preventing overfitting. Clearly, in this case the network is indeed overfitting, as we see 91% train accuracy and less than 70% test accuracy. It may also need adjustments to the number of MaxPooling layers, filter size, and padding. \n",
    "\n",
    "Still, on a complex problem such as image classification, it does reasonably well. Test accuracy tops out at 69%, considerably better than the best fully connected neural networks of the previous notebook. By adding just two Convulutional 2D layers, an increase of 19% accuracy was achieved. \n",
    "\n",
    "Let's see if investigating LeNet's simple architecture, adding some dropout, and ensuring that the image size is not dropping to much could have a positive impact on this networks ability to classify images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (5,5), padding='same', input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(.25))\n",
    "\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        2432      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               6423040   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 6,449,098\n",
      "Trainable params: 6,449,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 23s 468us/step - loss: 1.7102 - acc: 0.3849 - val_loss: 1.4496 - val_acc: 0.4882\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 22s 436us/step - loss: 1.4176 - acc: 0.4946 - val_loss: 1.2758 - val_acc: 0.5431\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 22s 436us/step - loss: 1.2962 - acc: 0.5379 - val_loss: 1.2490 - val_acc: 0.5604\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 22s 436us/step - loss: 1.2014 - acc: 0.5747 - val_loss: 1.1252 - val_acc: 0.6065\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 22s 436us/step - loss: 1.1311 - acc: 0.6033 - val_loss: 1.1054 - val_acc: 0.6102\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 22s 436us/step - loss: 1.0745 - acc: 0.6232 - val_loss: 1.0789 - val_acc: 0.6195\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 22s 436us/step - loss: 0.9042 - acc: 0.6912 - val_loss: 0.9988 - val_acc: 0.6723\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 22s 436us/step - loss: 0.8946 - acc: 0.6972 - val_loss: 1.0539 - val_acc: 0.6548\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 22s 437us/step - loss: 0.8841 - acc: 0.7007 - val_loss: 1.0914 - val_acc: 0.6806\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 22s 437us/step - loss: 0.8795 - acc: 0.7015 - val_loss: 1.0822 - val_acc: 0.6821\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 22s 436us/step - loss: 0.8701 - acc: 0.7086 - val_loss: 1.0359 - val_acc: 0.6625\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 22s 436us/step - loss: 0.8675 - acc: 0.7095 - val_loss: 1.1428 - val_acc: 0.6795\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 22s 436us/step - loss: 0.8594 - acc: 0.7125 - val_loss: 1.1063 - val_acc: 0.6260\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 22s 436us/step - loss: 0.8593 - acc: 0.7127 - val_loss: 1.1332 - val_acc: 0.6751\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 22s 436us/step - loss: 0.8597 - acc: 0.7132 - val_loss: 1.1394 - val_acc: 0.6646\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "lenet_hist_2 = model.fit(x_train, y_train,\n",
    "              batch_size=32,\n",
    "              epochs=100,\n",
    "              validation_data=(x_test, y_test),\n",
    "              callbacks=[early_stop, tb],\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not yet seeing any increase in performace. In fact, adding these more complex features on a relatively simple network hurt its overall validation score. Let's try adding just one more Conv2D layer and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 32)        2432      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               4719104   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 4,782,090\n",
      "Trainable params: 4,782,090\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (5,5), padding='same', input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(.25))\n",
    "\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 22s 440us/step - loss: 1.7482 - acc: 0.3636 - val_loss: 1.4489 - val_acc: 0.4838\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 22s 437us/step - loss: 1.4228 - acc: 0.4882 - val_loss: 1.3297 - val_acc: 0.5188\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 22s 437us/step - loss: 1.2872 - acc: 0.5418 - val_loss: 1.2033 - val_acc: 0.5792\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 22s 436us/step - loss: 1.1886 - acc: 0.5819 - val_loss: 1.0850 - val_acc: 0.6148\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 22s 439us/step - loss: 1.1069 - acc: 0.6102 - val_loss: 1.0884 - val_acc: 0.6128\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 22s 437us/step - loss: 1.0412 - acc: 0.6344 - val_loss: 1.0035 - val_acc: 0.6467\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 22s 437us/step - loss: 0.9867 - acc: 0.6561 - val_loss: 1.0043 - val_acc: 0.6448\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 22s 437us/step - loss: 0.9502 - acc: 0.6703 - val_loss: 0.9796 - val_acc: 0.6568\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 22s 437us/step - loss: 0.9142 - acc: 0.6822 - val_loss: 0.9117 - val_acc: 0.6801\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 22s 438us/step - loss: 0.8810 - acc: 0.6946 - val_loss: 0.8995 - val_acc: 0.6916\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 22s 436us/step - loss: 0.8664 - acc: 0.7006 - val_loss: 0.9433 - val_acc: 0.6786\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 22s 436us/step - loss: 0.8479 - acc: 0.7094 - val_loss: 0.9627 - val_acc: 0.6872\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 22s 437us/step - loss: 0.8317 - acc: 0.7161 - val_loss: 0.9067 - val_acc: 0.6911\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 22s 436us/step - loss: 0.8220 - acc: 0.7199 - val_loss: 0.8513 - val_acc: 0.7111\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 22s 436us/step - loss: 0.8138 - acc: 0.7211 - val_loss: 0.8755 - val_acc: 0.7048\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 22s 437us/step - loss: 0.8044 - acc: 0.7253 - val_loss: 0.8900 - val_acc: 0.7011\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 22s 436us/step - loss: 0.7995 - acc: 0.7279 - val_loss: 0.8938 - val_acc: 0.7000\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 22s 437us/step - loss: 0.7968 - acc: 0.7281 - val_loss: 0.8857 - val_acc: 0.7078\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 22s 436us/step - loss: 0.7937 - acc: 0.7330 - val_loss: 0.8896 - val_acc: 0.7085\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "lenet_hist_3 = model.fit(x_train, y_train,\n",
    "              batch_size=32,\n",
    "              epochs=100,\n",
    "              validation_data=(x_test, y_test),\n",
    "              callbacks=[early_stop, tb],\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small changes can have huge effects on a neural networks ability to learn the data. Previously, I tried the same exact architecture as above, but included ```padding='same'``` on the second Convulutional2D layer. That caused the model to fail, producing only 10% accuracy. I do not know why removing padding on this layer so greatly impacted the models ability to learn, but conjecture that it had to do with the addition of zeros along the edges of the images in the second layer causing information to be lost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_47 (Conv2D)           (None, 32, 32, 32)        2432      \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 12, 12, 32)        18464     \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 512)               2359808   \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,441,258\n",
      "Trainable params: 2,441,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (5,5), padding='same', input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(32, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 25s 509us/step - loss: 14.5179 - acc: 0.0993 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 25s 504us/step - loss: 14.4850 - acc: 0.1013 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 25s 505us/step - loss: 14.5027 - acc: 0.1002 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 25s 504us/step - loss: 14.5127 - acc: 0.0996 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 25s 505us/step - loss: 14.5137 - acc: 0.0995 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 25s 504us/step - loss: 14.5031 - acc: 0.1002 - val_loss: 14.5063 - val_acc: 0.1000\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.RMSprop(lr=0.1, decay=1e-6)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "lenet_hist_4 = model.fit(x_train, y_train,\n",
    "              batch_size=32,\n",
    "              epochs=10,\n",
    "              validation_data=(x_test, y_test),\n",
    "              callbacks=[early_stop, tb],\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strangely, adding just one more convulutional 2D layer kills this models ability to learn the images. Neural Networks, although powerful, are clearly extremely sensitive to small changes in their architecture. Not only that, but with so many different variations and parameters to tune, neural networks really are not something just to throw at any problem a data scientist might encounter. \n",
    "\n",
    "Before we add another Conv2D layer, what would happen if we added a second fully connected layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_55 (Conv2D)           (None, 32, 32, 32)        2432      \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1024)              9438208   \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_90 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 10,035,242\n",
      "Trainable params: 10,035,242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (5,5), padding='same', input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(.25))\n",
    "\n",
    "model.add(Conv2D(32, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(.25))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 33s 664us/step - loss: 1.7735 - acc: 0.3482 - val_loss: 1.4820 - val_acc: 0.4686\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 33s 658us/step - loss: 1.4407 - acc: 0.4801 - val_loss: 1.3119 - val_acc: 0.5310\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 33s 657us/step - loss: 1.2860 - acc: 0.5425 - val_loss: 1.2177 - val_acc: 0.5670\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 33s 658us/step - loss: 1.1749 - acc: 0.5836 - val_loss: 1.1317 - val_acc: 0.6100\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 33s 657us/step - loss: 1.0865 - acc: 0.6142 - val_loss: 1.0738 - val_acc: 0.6272\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 33s 658us/step - loss: 1.0163 - acc: 0.6440 - val_loss: 1.0345 - val_acc: 0.6412\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 33s 658us/step - loss: 0.9641 - acc: 0.6620 - val_loss: 0.9774 - val_acc: 0.6692\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 33s 659us/step - loss: 0.9178 - acc: 0.6805 - val_loss: 1.0498 - val_acc: 0.6523\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 33s 657us/step - loss: 0.8908 - acc: 0.6925 - val_loss: 0.9514 - val_acc: 0.6905\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 33s 658us/step - loss: 0.8641 - acc: 0.7001 - val_loss: 0.9560 - val_acc: 0.6852\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 33s 656us/step - loss: 0.8491 - acc: 0.7072 - val_loss: 1.3416 - val_acc: 0.6512\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 33s 657us/step - loss: 0.8458 - acc: 0.7096 - val_loss: 1.0350 - val_acc: 0.6847\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 33s 657us/step - loss: 0.8410 - acc: 0.7103 - val_loss: 0.9461 - val_acc: 0.6995\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 33s 656us/step - loss: 0.8333 - acc: 0.7135 - val_loss: 1.0061 - val_acc: 0.6879\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 33s 657us/step - loss: 0.8289 - acc: 0.7151 - val_loss: 0.9774 - val_acc: 0.6825\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 33s 655us/step - loss: 0.8208 - acc: 0.7170 - val_loss: 0.9099 - val_acc: 0.7042\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 33s 657us/step - loss: 0.8253 - acc: 0.7185 - val_loss: 1.0981 - val_acc: 0.6772\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 33s 656us/step - loss: 0.8169 - acc: 0.7194 - val_loss: 0.8922 - val_acc: 0.7090\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 33s 657us/step - loss: 0.8114 - acc: 0.7235 - val_loss: 0.9626 - val_acc: 0.7094\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 33s 656us/step - loss: 0.8154 - acc: 0.7214 - val_loss: 0.9160 - val_acc: 0.7011\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 33s 657us/step - loss: 0.8070 - acc: 0.7244 - val_loss: 0.9816 - val_acc: 0.7000\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 33s 657us/step - loss: 0.8074 - acc: 0.7262 - val_loss: 1.0896 - val_acc: 0.6860\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 33s 658us/step - loss: 0.8097 - acc: 0.7260 - val_loss: 1.0634 - val_acc: 0.6916\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 33s 657us/step - loss: 0.8093 - acc: 0.7256 - val_loss: 0.9203 - val_acc: 0.6931\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "lenet_hist_5 = model.fit(x_train, y_train,\n",
    "              batch_size=32,\n",
    "              epochs=100,\n",
    "              validation_data=(x_test, y_test),\n",
    "              callbacks=[early_stop, tb],\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3), padding='same', input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(32, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(64, (3,3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3072))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_59 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_91 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_92 (Activation)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 7, 7, 32)          128       \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "activation_93 (Activation)   (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 5, 5, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_94 (Activation)   (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_95 (Activation)   (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 3072)              199680    \n",
      "_________________________________________________________________\n",
      "activation_96 (Activation)   (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "activation_97 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_98 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,880,938\n",
      "Trainable params: 1,880,810\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 23s 456us/step - loss: 1.5047 - acc: 0.4488 - val_loss: 1.2627 - val_acc: 0.5439\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 22s 433us/step - loss: 1.1910 - acc: 0.5709 - val_loss: 1.2206 - val_acc: 0.5634\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 22s 433us/step - loss: 0.7037 - acc: 0.7512 - val_loss: 1.0561 - val_acc: 0.6556\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 22s 432us/step - loss: 0.6575 - acc: 0.7704 - val_loss: 1.0671 - val_acc: 0.6544\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 22s 434us/step - loss: 0.6124 - acc: 0.7845 - val_loss: 1.0614 - val_acc: 0.6569\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 22s 432us/step - loss: 0.5708 - acc: 0.7984 - val_loss: 1.1322 - val_acc: 0.6571\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 22s 434us/step - loss: 0.5311 - acc: 0.8139 - val_loss: 1.0487 - val_acc: 0.6708\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 22s 435us/step - loss: 0.4929 - acc: 0.8268 - val_loss: 1.1607 - val_acc: 0.6676\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 22s 433us/step - loss: 0.4568 - acc: 0.8405 - val_loss: 1.2529 - val_acc: 0.6513\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 22s 434us/step - loss: 0.4256 - acc: 0.8508 - val_loss: 1.1988 - val_acc: 0.6620\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 22s 432us/step - loss: 0.3935 - acc: 0.8614 - val_loss: 1.2427 - val_acc: 0.6757\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 22s 433us/step - loss: 0.3658 - acc: 0.8734 - val_loss: 1.2238 - val_acc: 0.6649\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 22s 432us/step - loss: 0.3384 - acc: 0.8796 - val_loss: 1.3550 - val_acc: 0.6601\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 22s 432us/step - loss: 0.3158 - acc: 0.8886 - val_loss: 1.4330 - val_acc: 0.6680\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 22s 433us/step - loss: 0.2982 - acc: 0.8954 - val_loss: 1.4111 - val_acc: 0.6667\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 22s 433us/step - loss: 0.2757 - acc: 0.9025 - val_loss: 1.6516 - val_acc: 0.6548\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3e32cb57b8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "              batch_size=32,\n",
    "              epochs=25,\n",
    "              validation_data=(x_test, y_test),\n",
    "              callbacks=[early_stop],\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 140us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.6516393534660339, 0.65480000000000005]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model appears to begin offering promising results. On training data it performs extremely well, reaching accuracy of .91 and only .23 loss. However, when validation scores are considered, it does not appear to be learning the data better. In fact, val scores peak around Epoch 13, at .67.\n",
    "\n",
    "Compared to the baseline models I have considered so far, this model is not doing terrible, but there still remains a lot of room for improvement. \n",
    "\n",
    "A notable difference between this model and the example model fit in notebook one is the presence of batch normalization layers instead of dropout layers. These layers are both importation layers for preventing overfitting. \n",
    "\n",
    "Dropout layers prevent overfitting by randomly resetting a fraction of the inputs to zero at each layer. This helps by reducing the noise - think of it as decreasing the resolution or sharpness of the image - so that the true features that make up a shape can be extracted. For example, human faces are easily recognizable to us. However, no two single humans faces have the same exact shape. By randomly dropping some of the uniqueness of each input, the true features may be extracted. \n",
    "\n",
    "As a final addition to this notebook, I will now fit a variation of the AlexNet model that incorporates these dropout layers while removing the normalization layers in an attempt to produce better results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3), padding='same', input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(32, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3072))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_64 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_99 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_65 (Conv2D)           (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_100 (Activation)  (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_66 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "activation_101 (Activation)  (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_67 (Conv2D)           (None, 5, 5, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_102 (Activation)  (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_68 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_103 (Activation)  (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 3072)              199680    \n",
      "_________________________________________________________________\n",
      "activation_104 (Activation)  (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "activation_105 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_106 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,880,682\n",
      "Trainable params: 1,880,682\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 20s 404us/step - loss: 1.9121 - acc: 0.2802 - val_loss: 1.7006 - val_acc: 0.3917\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 1.6073 - acc: 0.4109 - val_loss: 1.5371 - val_acc: 0.4409\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 1.4691 - acc: 0.4632 - val_loss: 1.4066 - val_acc: 0.4899\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 1.3796 - acc: 0.4987 - val_loss: 1.3563 - val_acc: 0.5181\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 1.0962 - acc: 0.6095 - val_loss: 1.0853 - val_acc: 0.6119\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 1.0681 - acc: 0.6184 - val_loss: 1.1114 - val_acc: 0.6100\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 19s 384us/step - loss: 1.0329 - acc: 0.6306 - val_loss: 0.9744 - val_acc: 0.6496\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 19s 384us/step - loss: 1.0109 - acc: 0.6393 - val_loss: 1.1418 - val_acc: 0.6041\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 19s 384us/step - loss: 0.9865 - acc: 0.6500 - val_loss: 1.0517 - val_acc: 0.6300\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.9680 - acc: 0.6562 - val_loss: 1.0131 - val_acc: 0.6466\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 19s 384us/step - loss: 0.9492 - acc: 0.6640 - val_loss: 1.0018 - val_acc: 0.6444\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.9295 - acc: 0.6699 - val_loss: 0.9463 - val_acc: 0.6687\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 19s 384us/step - loss: 0.9134 - acc: 0.6759 - val_loss: 0.9601 - val_acc: 0.6666\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 0.8947 - acc: 0.6827 - val_loss: 0.9869 - val_acc: 0.6613\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.8845 - acc: 0.6889 - val_loss: 0.9330 - val_acc: 0.6759\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 0.8706 - acc: 0.6934 - val_loss: 0.9463 - val_acc: 0.6745\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.8549 - acc: 0.6984 - val_loss: 1.1097 - val_acc: 0.6492\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.8466 - acc: 0.7033 - val_loss: 0.9527 - val_acc: 0.6829\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 0.8381 - acc: 0.7059 - val_loss: 1.2138 - val_acc: 0.6319\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 0.8279 - acc: 0.7115 - val_loss: 0.8961 - val_acc: 0.6906\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.8184 - acc: 0.7124 - val_loss: 0.9448 - val_acc: 0.6890\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 0.8132 - acc: 0.7171 - val_loss: 0.9115 - val_acc: 0.6954\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.8030 - acc: 0.7197 - val_loss: 1.0052 - val_acc: 0.6879\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.7981 - acc: 0.7207 - val_loss: 0.9803 - val_acc: 0.7000\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 0.7964 - acc: 0.7227 - val_loss: 1.0494 - val_acc: 0.6748\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.7885 - acc: 0.7245 - val_loss: 1.0938 - val_acc: 0.6817\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 0.7855 - acc: 0.7231 - val_loss: 0.9040 - val_acc: 0.7011\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.7843 - acc: 0.7274 - val_loss: 1.0963 - val_acc: 0.6744\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.7803 - acc: 0.7318 - val_loss: 0.9443 - val_acc: 0.7090\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 19s 384us/step - loss: 0.7758 - acc: 0.7339 - val_loss: 0.9012 - val_acc: 0.7175\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 0.7830 - acc: 0.7307 - val_loss: 0.9096 - val_acc: 0.6992\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.7756 - acc: 0.7329 - val_loss: 0.8978 - val_acc: 0.7169\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 19s 384us/step - loss: 0.7788 - acc: 0.7317 - val_loss: 0.9810 - val_acc: 0.6937\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.7783 - acc: 0.7343 - val_loss: 1.0369 - val_acc: 0.6822\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.7762 - acc: 0.7318 - val_loss: 0.9095 - val_acc: 0.7209\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.7740 - acc: 0.7334 - val_loss: 0.9079 - val_acc: 0.7100\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.7793 - acc: 0.7351 - val_loss: 0.8747 - val_acc: 0.7234\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.7764 - acc: 0.7328 - val_loss: 0.9256 - val_acc: 0.7261\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.7760 - acc: 0.7335 - val_loss: 0.9799 - val_acc: 0.6867\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.7865 - acc: 0.7345 - val_loss: 0.9199 - val_acc: 0.7091\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.7825 - acc: 0.7334 - val_loss: 0.8923 - val_acc: 0.7102\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.7793 - acc: 0.7365 - val_loss: 0.9429 - val_acc: 0.7032\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.7842 - acc: 0.7355 - val_loss: 0.9183 - val_acc: 0.6951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3e32098b38>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "              batch_size=32,\n",
    "              epochs=100,\n",
    "              validation_data=(x_test, y_test),\n",
    "              callbacks=[early_stop],\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding dropout does help the validation score slightly here, boosting it from .66 in the first iteration of the AlexNet model to just above .70 in this iteration. \n",
    "\n",
    "After reading through the paper located here http://vision.stanford.edu/teaching/cs231b_spring1415/slides/alexnet_tugce_kyunghee.pdf in greater depth, I made a few changes again to the model. Now I incorporate Normalization layers in the first two layers of the model, before applying MaxPooling instead of after. I also adjusted the size of the Fully Connected layers at the end and added to new Dropout .5 layers after each, as was suggested in order to decrease overfitting in the AlexNet published paper.\n",
    "\n",
    "By the end of the 7 convulutional layers, 64 filters have been created. Each of these 64 filters then connects to each of the fully connected neurons. The neurons learn to give different weightings to each of the 64 shape filters in order to put together ideas about what shapes form together to create certain image classifications. This process happens through two layers, and then final decisions are made. Dropout is introduced in these layers to prevent overfitting in the training model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(24, (5,5), padding='same', input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, (5,5)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), padding=\"same\"))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(32, (3,3), padding=\"same\"))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_69 (Conv2D)           (None, 32, 32, 24)        1824      \n",
      "_________________________________________________________________\n",
      "activation_107 (Activation)  (None, 32, 32, 24)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 32, 24)        96        \n",
      "_________________________________________________________________\n",
      "conv2d_70 (Conv2D)           (None, 28, 28, 64)        38464     \n",
      "_________________________________________________________________\n",
      "activation_108 (Activation)  (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_71 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_109 (Activation)  (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_72 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_110 (Activation)  (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_73 (Conv2D)           (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "activation_111 (Activation)  (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "activation_112 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_113 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_114 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 3,612,522\n",
      "Trainable params: 3,612,346\n",
      "Non-trainable params: 176\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 39s 776us/step - loss: 1.6092 - acc: 0.4132 - val_loss: 1.3159 - val_acc: 0.5290\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 37s 750us/step - loss: 1.2343 - acc: 0.5645 - val_loss: 1.0755 - val_acc: 0.6176\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 38s 750us/step - loss: 1.0447 - acc: 0.6343 - val_loss: 1.0018 - val_acc: 0.6532\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 37s 750us/step - loss: 0.9209 - acc: 0.6814 - val_loss: 0.9908 - val_acc: 0.6623\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 37s 750us/step - loss: 0.8219 - acc: 0.7163 - val_loss: 0.9516 - val_acc: 0.6921\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 38s 751us/step - loss: 0.7509 - acc: 0.7432 - val_loss: 0.8882 - val_acc: 0.7039\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 38s 751us/step - loss: 0.6977 - acc: 0.7672 - val_loss: 0.9139 - val_acc: 0.6945\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 38s 751us/step - loss: 0.6556 - acc: 0.7815 - val_loss: 0.9676 - val_acc: 0.6809\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 38s 750us/step - loss: 0.6241 - acc: 0.7937 - val_loss: 0.9588 - val_acc: 0.7039\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 38s 752us/step - loss: 0.6044 - acc: 0.8027 - val_loss: 0.9297 - val_acc: 0.7139\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 38s 750us/step - loss: 0.5954 - acc: 0.8080 - val_loss: 1.0517 - val_acc: 0.7072\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 37s 749us/step - loss: 0.5964 - acc: 0.8082 - val_loss: 1.0744 - val_acc: 0.7029\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 37s 750us/step - loss: 0.6009 - acc: 0.8056 - val_loss: 1.2482 - val_acc: 0.6733\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 38s 750us/step - loss: 0.5989 - acc: 0.8079 - val_loss: 0.9917 - val_acc: 0.7031\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 37s 750us/step - loss: 0.6085 - acc: 0.8050 - val_loss: 1.0826 - val_acc: 0.6916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3e31888048>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "              batch_size=32,\n",
    "              epochs=100,\n",
    "              validation_data=(x_test, y_test),\n",
    "              callbacks=[early_stop],\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (5,5), padding='same', input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), padding=\"same\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (5,5), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), padding='same'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_74 (Conv2D)           (None, 32, 32, 64)        4864      \n",
      "_________________________________________________________________\n",
      "activation_115 (Activation)  (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_75 (Conv2D)           (None, 16, 16, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_116 (Activation)  (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "activation_117 (Activation)  (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "activation_118 (Activation)  (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 10)                40970     \n",
      "_________________________________________________________________\n",
      "activation_119 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 33,711,434\n",
      "Trainable params: 33,711,178\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 76s 2ms/step - loss: 1.7085 - acc: 0.4295 - val_loss: 1.3421 - val_acc: 0.5588\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 75s 1ms/step - loss: 1.2709 - acc: 0.5611 - val_loss: 1.2717 - val_acc: 0.6025\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 75s 1ms/step - loss: 1.1198 - acc: 0.6174 - val_loss: 2.2229 - val_acc: 0.5631\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 75s 1ms/step - loss: 1.0438 - acc: 0.6480 - val_loss: 1.1556 - val_acc: 0.6496\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 75s 1ms/step - loss: 0.9961 - acc: 0.6709 - val_loss: 1.1010 - val_acc: 0.6646\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 75s 1ms/step - loss: 0.9629 - acc: 0.6832 - val_loss: 1.1407 - val_acc: 0.6297\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 75s 1ms/step - loss: 0.9368 - acc: 0.6958 - val_loss: 1.1625 - val_acc: 0.6621\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 75s 1ms/step - loss: 0.9120 - acc: 0.7071 - val_loss: 1.1284 - val_acc: 0.6541\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 75s 1ms/step - loss: 0.8892 - acc: 0.7142 - val_loss: 1.0827 - val_acc: 0.6938\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 75s 1ms/step - loss: 0.8743 - acc: 0.7222 - val_loss: 1.3287 - val_acc: 0.6557\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 75s 1ms/step - loss: 0.8534 - acc: 0.7293 - val_loss: 1.3319 - val_acc: 0.6696\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 75s 1ms/step - loss: 0.8308 - acc: 0.7395 - val_loss: 2.8413 - val_acc: 0.5631\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 75s 1ms/step - loss: 0.8189 - acc: 0.7456 - val_loss: 1.6306 - val_acc: 0.6146\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 75s 1ms/step - loss: 0.8090 - acc: 0.7509 - val_loss: 1.1998 - val_acc: 0.6552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3e30f5aac8>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "              batch_size=32,\n",
    "              epochs=100,\n",
    "              validation_data=(x_test, y_test),\n",
    "              callbacks=[early_stop],\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (5,5), padding='same', input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (5,5)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), padding=\"same\"))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(32, (3,3), padding=\"same\"))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_76 (Conv2D)           (None, 32, 32, 32)        2432      \n",
      "_________________________________________________________________\n",
      "activation_120 (Activation)  (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_77 (Conv2D)           (None, 12, 12, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_121 (Activation)  (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_78 (Conv2D)           (None, 6, 6, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_122 (Activation)  (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_79 (Conv2D)           (None, 6, 6, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_123 (Activation)  (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_80 (Conv2D)           (None, 6, 6, 32)          18464     \n",
      "_________________________________________________________________\n",
      "activation_124 (Activation)  (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 512)               590336    \n",
      "_________________________________________________________________\n",
      "activation_125 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_126 (Activation)  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_127 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,004,522\n",
      "Trainable params: 1,004,330\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 25s 492us/step - loss: 1.7671 - acc: 0.3402 - val_loss: 1.4886 - val_acc: 0.4647\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 23s 462us/step - loss: 1.3958 - acc: 0.4926 - val_loss: 1.3164 - val_acc: 0.5303\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 1.2499 - acc: 0.5499 - val_loss: 1.3401 - val_acc: 0.5477\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 1.1465 - acc: 0.5905 - val_loss: 1.1713 - val_acc: 0.5945\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 23s 462us/step - loss: 1.0707 - acc: 0.6225 - val_loss: 1.1259 - val_acc: 0.6099\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 23s 462us/step - loss: 1.0118 - acc: 0.6441 - val_loss: 1.3004 - val_acc: 0.5813\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 23s 462us/step - loss: 0.9654 - acc: 0.6630 - val_loss: 1.0649 - val_acc: 0.6407\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 23s 463us/step - loss: 0.9189 - acc: 0.6792 - val_loss: 1.1596 - val_acc: 0.6468\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 23s 462us/step - loss: 0.8826 - acc: 0.6938 - val_loss: 1.1165 - val_acc: 0.6677\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 23s 462us/step - loss: 0.8520 - acc: 0.7064 - val_loss: 0.9584 - val_acc: 0.6830\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.8273 - acc: 0.7148 - val_loss: 0.9884 - val_acc: 0.6838\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.8138 - acc: 0.7232 - val_loss: 0.9954 - val_acc: 0.6964\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.7934 - acc: 0.7306 - val_loss: 1.1019 - val_acc: 0.6783\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.7850 - acc: 0.7330 - val_loss: 1.0832 - val_acc: 0.6889\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 23s 464us/step - loss: 0.7642 - acc: 0.7413 - val_loss: 1.1712 - val_acc: 0.6764\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 0.7682 - acc: 0.7420 - val_loss: 1.2721 - val_acc: 0.6668\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 23s 466us/step - loss: 0.7600 - acc: 0.7461 - val_loss: 1.1391 - val_acc: 0.6953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3e3079c6a0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "              batch_size=32,\n",
    "              epochs=100,\n",
    "              validation_data=(x_test, y_test),\n",
    "              callbacks=[early_stop],\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 165us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1390913041114807, 0.69530000000000003]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
